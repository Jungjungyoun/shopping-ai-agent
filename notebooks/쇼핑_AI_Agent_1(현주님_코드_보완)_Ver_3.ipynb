{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„"
      ],
      "metadata": {
        "id": "kzMZtRgtIMQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "xbztIIP3K7AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 1: ë§¤íŠ¸ë¦¬ìŠ¤ êµ¬ë§¤ ê°€ì´ë“œ AI Agent - í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„\n",
        "\n",
        "# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install transformers\n",
        "!pip install sentence-transformers\n",
        "!pip install chromadb\n",
        "!pip install streamlit\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqpbHPMQIWAm",
        "outputId": "a7899ebe-2928-43df-f3cb-f7a57fe96c0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.12)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.5)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.55b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.34.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.72.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (33.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.34.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.55b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.55b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.55b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.55b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.32.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) ë¼ì´ë¸ŒëŸ¬ë¦¬ import"
      ],
      "metadata": {
        "id": "uoGnNjPCK20X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Q5w8BsIY2W",
        "outputId": "6f0d78ca-4b56-45c4-c3d6-a8cd6c191d75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Google Drive ë§ˆìš´íŠ¸ ë° ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° ë¡œë“œ"
      ],
      "metadata": {
        "id": "moxjlV-AKzef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Google Drive ë§ˆìš´íŠ¸ ë° ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° ë¡œë“œ\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Drive ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QmPqgpgpKxta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6edf9c6-a561-40e5-afed-5b5eec35751b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° íŒŒì¼ ê²½ë¡œ í™•ì¸ ë° ë¡œë“œ\n",
        "data_path = '/content/data_mattress_1000.json'\n",
        "\n",
        "try:\n",
        "    # JSON íŒŒì¼ ë¡œë“œ\n",
        "    with open(data_path, 'r', encoding='utf-8') as f:\n",
        "        mattress_data = json.load(f)\n",
        "\n",
        "    print(f\"âœ… ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“Š ì´ ë§¤íŠ¸ë¦¬ìŠ¤ ê°œìˆ˜: {len(mattress_data['mattresses'])}ê°œ\")\n",
        "\n",
        "    # ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
        "    print(\"\\nğŸ“‹ ë°ì´í„° êµ¬ì¡° í™•ì¸:\")\n",
        "    print(f\"- ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„°: {len(mattress_data['mattresses'])}ê°œ\")\n",
        "    print(f\"- êµ¬ë§¤ ê°€ì´ë“œ í¬í•¨: {'buying_guide' in mattress_data}\")\n",
        "\n",
        "    # ì²« ë²ˆì§¸ ë§¤íŠ¸ë¦¬ìŠ¤ ì •ë³´ ë¯¸ë¦¬ë³´ê¸°\n",
        "    first_mattress = mattress_data['mattresses'][0]\n",
        "    print(f\"\\nğŸ›ï¸ ì²« ë²ˆì§¸ ë§¤íŠ¸ë¦¬ìŠ¤ ì˜ˆì‹œ:\")\n",
        "    print(f\"- ì´ë¦„: {first_mattress['name']}\")\n",
        "    print(f\"- ë¸Œëœë“œ: {first_mattress['brand']}\")\n",
        "    print(f\"- íƒ€ì…: {first_mattress['type']}\")\n",
        "    print(f\"- ê°€ê²©: {first_mattress['price']:,}ì›\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:\")\n",
        "    print(\"1. Google Driveì— data_mattress.json íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸\")\n",
        "    print(\"2. íŒŒì¼ ê²½ë¡œê°€ /content/data_mattress.jsonì¸ì§€ í™•ì¸\")\n",
        "    print(\"3. íŒŒì¼ ê¶Œí•œ ì„¤ì • í™•ì¸\")\n",
        "\n",
        "    # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ ëª©ë¡ ì¶œë ¥\n",
        "    print(\"\\nğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬ íŒŒì¼ ëª©ë¡:\")\n",
        "    for file in os.listdir('/content/'):\n",
        "        print(f\"  - {file}\")\n",
        "\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"âŒ JSON íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜: {e}\")\n",
        "    print(\"íŒŒì¼ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv4ceWqsIa5e",
        "outputId": "d5c525dd-3013-4499-bf91-66624b39fff6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\n",
            "ğŸ“Š ì´ ë§¤íŠ¸ë¦¬ìŠ¤ ê°œìˆ˜: 1000ê°œ\n",
            "\n",
            "ğŸ“‹ ë°ì´í„° êµ¬ì¡° í™•ì¸:\n",
            "- ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„°: 1000ê°œ\n",
            "- êµ¬ë§¤ ê°€ì´ë“œ í¬í•¨: True\n",
            "\n",
            "ğŸ›ï¸ ì²« ë²ˆì§¸ ë§¤íŠ¸ë¦¬ìŠ¤ ì˜ˆì‹œ:\n",
            "- ì´ë¦„: KOOLON LATEX LINE ëª¨ë¸ 91\n",
            "- ë¸Œëœë“œ: KOOLON\n",
            "- íƒ€ì…: ë©”ëª¨ë¦¬í¼\n",
            "- ê°€ê²©: 1,277,728ì›\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHrzKODpH18e",
        "outputId": "659f5d04-0a5a-4783-9808-e3d6a789eab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\n",
            "ğŸ“Š ì²˜ë¦¬ëœ ë§¤íŠ¸ë¦¬ìŠ¤ ê°œìˆ˜: 1000ê°œ\n",
            "\n",
            "ğŸ” ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n",
            "ID: 43f4bc25-a73a-4e85-a023-34553c2568ec\n",
            "ì´ë¦„: KOOLON LATEX LINE ëª¨ë¸ 91\n",
            "ê²€ìƒ‰í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): ë§¤íŠ¸ë¦¬ìŠ¤ëª…: KOOLON LATEX LINE ëª¨ë¸ 91\n",
            "        ë¸Œëœë“œ: KOOLON\n",
            "        ì¢…ë¥˜: ë©”ëª¨ë¦¬í¼\n",
            "        ê°€ê²©: 1277728ì›\n",
            "        ë‹¨ë‹¨í•¨: í•˜ë“œ\n",
            "        ë‘ê»˜: 28cm\n",
            "        íŠ¹ì§•: ì—ì§€ì„œí¬íŠ¸, í†µê¸°ì„± ìš°ìˆ˜, ì›€ì§ì„ ì°¨ë‹¨, í•­ê· ì²˜ë¦¬, ë¼í…ìŠ¤ì¸µ\n",
            "        ì¶”ì²œëŒ€ìƒ: í—ˆë¦¬í†µì¦ ì™„í™”, ì»¤í”Œ\n",
            "      ...\n",
            "\n",
            "ğŸ’° ê°€ê²© ë¶„í¬:\n",
            "- ìµœì €ê°€: 153,726ì›\n",
            "- ìµœê³ ê°€: 4,999,744ì›\n",
            "- í‰ê· ê°€: 2,542,938ì›\n",
            "\n",
            "ğŸ›ï¸ ë§¤íŠ¸ë¦¬ìŠ¤ íƒ€ì…ë³„ ë¶„í¬:\n",
            "- ë©”ëª¨ë¦¬í¼: 214ê°œ\n",
            "- ìŠ¤í”„ë§: 205ê°œ\n",
            "- ì ¤ë©”ëª¨ë¦¬í¼: 204ê°œ\n",
            "- í•˜ì´ë¸Œë¦¬ë“œ: 190ê°œ\n",
            "- ë¼í…ìŠ¤: 187ê°œ\n",
            "\n",
            "==================================================\n",
            "âœ… Phase 1 ì™„ë£Œ!\n",
            "ë‹¤ìŒ ë‹¨ê³„: Phase 2 - RAG ì‹œìŠ¤í…œ êµ¬ì¶• (ChromaDB + ì„ë² ë”©)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# 4. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„ì„\n",
        "def preprocess_mattress_data(data):\n",
        "    \"\"\"ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„°ë¥¼ AI Agentì—ì„œ ì‚¬ìš©í•˜ê¸° ì‰½ê²Œ ì „ì²˜ë¦¬\"\"\"\n",
        "\n",
        "    mattresses = data['mattresses']\n",
        "    processed_data = []\n",
        "\n",
        "    for mattress in mattresses:\n",
        "        # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„± (ì„ë² ë”©ì— ì‚¬ìš©ë  í…ìŠ¤íŠ¸)\n",
        "        search_text = f\"\"\"\n",
        "        ë§¤íŠ¸ë¦¬ìŠ¤ëª…: {mattress['name']}\n",
        "        ë¸Œëœë“œ: {mattress['brand']}\n",
        "        ì¢…ë¥˜: {mattress['type']}\n",
        "        ê°€ê²©: {mattress['price']}ì›\n",
        "        ë‹¨ë‹¨í•¨: {mattress['firmness']}\n",
        "        ë‘ê»˜: {mattress['thickness']}\n",
        "        íŠ¹ì§•: {', '.join(mattress['features'])}\n",
        "        ì¶”ì²œëŒ€ìƒ: {', '.join(mattress['recommended_for'])}\n",
        "        ë¹„ì¶”ì²œëŒ€ìƒ: {', '.join(mattress['not_recommended_for'])}\n",
        "        ì¥ì : {', '.join(mattress['pros'])}\n",
        "        ë‹¨ì : {', '.join(mattress['cons'])}\n",
        "        ì„¤ëª…: {mattress['description']}\n",
        "        ì‚¬ìš©ìë¦¬ë·°: {mattress['user_reviews']}\n",
        "        \"\"\".strip()\n",
        "\n",
        "        # ì²˜ë¦¬ëœ ë°ì´í„° êµ¬ì¡°\n",
        "        processed_mattress = {\n",
        "            'id': mattress['id'],\n",
        "            'name': mattress['name'],\n",
        "            'brand': mattress['brand'],\n",
        "            'type': mattress['type'],\n",
        "            'price': mattress['price'],\n",
        "            'firmness': mattress['firmness'],\n",
        "            'search_text': search_text,\n",
        "            'original_data': mattress  # ì›ë³¸ ë°ì´í„° ë³´ì¡´\n",
        "        }\n",
        "\n",
        "        processed_data.append(processed_mattress)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "# ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰\n",
        "if 'mattress_data' in locals():\n",
        "    processed_mattresses = preprocess_mattress_data(mattress_data)\n",
        "\n",
        "    print(\"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“Š ì²˜ë¦¬ëœ ë§¤íŠ¸ë¦¬ìŠ¤ ê°œìˆ˜: {len(processed_mattresses)}ê°œ\")\n",
        "\n",
        "    # ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\n",
        "    print(\"\\nğŸ” ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
        "    sample = processed_mattresses[0]\n",
        "    print(f\"ID: {sample['id']}\")\n",
        "    print(f\"ì´ë¦„: {sample['name']}\")\n",
        "    print(f\"ê²€ìƒ‰í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): {sample['search_text'][:200]}...\")\n",
        "\n",
        "    # ê°€ê²©ëŒ€ë³„ ë¶„í¬ í™•ì¸\n",
        "    prices = [m['price'] for m in processed_mattresses]\n",
        "    print(f\"\\nğŸ’° ê°€ê²© ë¶„í¬:\")\n",
        "    print(f\"- ìµœì €ê°€: {min(prices):,}ì›\")\n",
        "    print(f\"- ìµœê³ ê°€: {max(prices):,}ì›\")\n",
        "    print(f\"- í‰ê· ê°€: {np.mean(prices):,.0f}ì›\")\n",
        "\n",
        "    # íƒ€ì…ë³„ ë¶„í¬\n",
        "    types = [m['type'] for m in processed_mattresses]\n",
        "    type_counts = pd.Series(types).value_counts()\n",
        "    print(f\"\\nğŸ›ï¸ ë§¤íŠ¸ë¦¬ìŠ¤ íƒ€ì…ë³„ ë¶„í¬:\")\n",
        "    for mattress_type, count in type_counts.items():\n",
        "        print(f\"- {mattress_type}: {count}ê°œ\")\n",
        "\n",
        "else:\n",
        "    print(\"âŒ ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"âœ… Phase 1 ì™„ë£Œ!\")\n",
        "print(\"ë‹¤ìŒ ë‹¨ê³„: Phase 2 - RAG ì‹œìŠ¤í…œ êµ¬ì¶• (ChromaDB + ì„ë² ë”©)\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. RAG ì‹œìŠ¤í…œ êµ¬ì¶•"
      ],
      "metadata": {
        "id": "gcZPXbr3MKkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
      ],
      "metadata": {
        "id": "tl0DM6jXM2yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 2: RAG ì‹œìŠ¤í…œ êµ¬ì¶• - ChromaDBì™€ ì„ë² ë”©\n",
        "\n",
        "# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
        "print(\"ğŸ“¦ RAG ì‹œìŠ¤í…œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜...\")\n",
        "\n",
        "!pip install chromadb sentence-transformers -q\n",
        "\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "import uuid\n",
        "\n",
        "print(\"âœ… RAG ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xScWCzTpM0IR",
        "outputId": "9874e42c-70d4-4adb-e371-1dd7312df9e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ RAG ì‹œìŠ¤í…œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜...\n",
            "âœ… RAG ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"
      ],
      "metadata": {
        "id": "xcZbII2OM7_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ\n",
        "print(\"\\nğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "print(\"ì‚¬ìš© ëª¨ë¸: sentence-transformers/all-MiniLM-L6-v2 (ë‹¤êµ­ì–´ ì§€ì›)\")\n",
        "\n",
        "try:\n",
        "    # í•œêµ­ì–´ë„ ì§€ì›í•˜ëŠ” ê²½ëŸ‰ ëª¨ë¸\n",
        "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    print(\"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
        "\n",
        "    # ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
        "    test_text = \"í…ŒìŠ¤íŠ¸ìš© í•œêµ­ì–´ ë¬¸ì¥ì…ë‹ˆë‹¤.\"\n",
        "    test_embedding = embedding_model.encode([test_text])\n",
        "    print(f\"ğŸ“Š ì„ë² ë”© ì°¨ì›: {test_embedding.shape[1]}ì°¨ì›\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ğŸ’¡ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mCpHHw-M_to",
        "outputId": "c0f36eb2-44f1-4dea-99f2-f7d9a8d86616"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...\n",
            "ì‚¬ìš© ëª¨ë¸: sentence-transformers/all-MiniLM-L6-v2 (ë‹¤êµ­ì–´ ì§€ì›)\n",
            "âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\n",
            "ğŸ“Š ì„ë² ë”© ì°¨ì›: 384ì°¨ì›\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"
      ],
      "metadata": {
        "id": "QaQtN935NBGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "print(\"\\nğŸ—„ï¸ ChromaDB ì´ˆê¸°í™”...\")\n",
        "\n",
        "try:\n",
        "    # ë©”ëª¨ë¦¬ ê¸°ë°˜ ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
        "    chroma_client = chromadb.Client()\n",
        "\n",
        "    # ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆë‹¤ë©´ ì‚­ì œ (ì¬ì‹¤í–‰ ì‹œ ì¶©ëŒ ë°©ì§€)\n",
        "    try:\n",
        "        chroma_client.delete_collection(\"mattress_collection\")\n",
        "        print(\"ğŸ”„ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±\n",
        "    collection = chroma_client.create_collection(\n",
        "        name=\"mattress_collection\",\n",
        "        metadata={\"description\": \"ë§¤íŠ¸ë¦¬ìŠ¤ êµ¬ë§¤ ê°€ì´ë“œìš© ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤\"}\n",
        "    )\n",
        "\n",
        "    print(\"âœ… ChromaDB ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“‹ ì»¬ë ‰ì…˜ëª…: mattress_collection\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifsG6uIMNFHM",
        "outputId": "876fc4b9-9959-41b8-83f9-3bbaccdffdb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ—„ï¸ ChromaDB ì´ˆê¸°í™”...\n",
            "âœ… ChromaDB ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ!\n",
            "ğŸ“‹ ì»¬ë ‰ì…˜ëª…: mattress_collection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ì—¬ ChromaDBì— ì €ì¥"
      ],
      "metadata": {
        "id": "nIyQJZSKNHYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ì—¬ ChromaDBì— ì €ì¥\n",
        "print(\"\\nğŸ”„ ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° ë²¡í„°í™” ë° ì €ì¥...\")\n",
        "\n",
        "def create_mattress_embeddings(mattress_data: Dict) -> bool:\n",
        "    \"\"\"ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ì—¬ ChromaDBì— ì €ì¥\"\"\"\n",
        "\n",
        "    try:\n",
        "        mattresses = mattress_data['mattresses']\n",
        "\n",
        "        # ê° ë§¤íŠ¸ë¦¬ìŠ¤ì— ëŒ€í•œ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ì¤€ë¹„\n",
        "        documents = []  # ì„ë² ë”©í•  í…ìŠ¤íŠ¸\n",
        "        metadatas = []  # ë©”íƒ€ë°ì´í„°\n",
        "        ids = []        # ê³ ìœ  ID\n",
        "\n",
        "        for mattress in mattresses:\n",
        "            # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„± (ë” ìƒì„¸í•˜ê²Œ)\n",
        "            search_text = f\"\"\"\n",
        "            ë§¤íŠ¸ë¦¬ìŠ¤ ì´ë¦„: {mattress.get('name', '')}\n",
        "            ë¸Œëœë“œ: {mattress.get('brand', '')}\n",
        "            ì¢…ë¥˜: {mattress.get('type', '')}\n",
        "            ê°€ê²©: {mattress.get('price', '')}ì›\n",
        "            ë‹¨ë‹¨í•¨: {mattress.get('firmness', '')}\n",
        "            ë‘ê»˜: {mattress.get('thickness', '')}\n",
        "            íŠ¹ì§•: {', '.join(mattress.get('features', []))}\n",
        "            ì¶”ì²œ ëŒ€ìƒ: {', '.join(mattress.get('recommended_for', []))}\n",
        "            ë¹„ì¶”ì²œ ëŒ€ìƒ: {', '.join(mattress.get('not_recommended_for', []))}\n",
        "            ì¬ë£Œ: {', '.join(mattress.get('materials', []))}\n",
        "            ì¥ì : {', '.join(mattress.get('pros', []))}\n",
        "            ë‹¨ì : {', '.join(mattress.get('cons', []))}\n",
        "            ìƒí’ˆ ì„¤ëª…: {mattress.get('description', '')}\n",
        "            ì‚¬ìš©ì ë¦¬ë·°: {mattress.get('user_reviews', '')}\n",
        "            \"\"\".strip()\n",
        "\n",
        "            # ë©”íƒ€ë°ì´í„° (ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‚¬ìš©í•  ì •ë³´)\n",
        "            metadata = {\n",
        "                'name': mattress.get('name', ''),\n",
        "                'brand': mattress.get('brand', ''),\n",
        "                'type': mattress.get('type', ''),\n",
        "                'price': mattress.get('price', 0),\n",
        "                'firmness': mattress.get('firmness', ''),\n",
        "                'id': mattress.get('id', '')\n",
        "            }\n",
        "\n",
        "            documents.append(search_text)\n",
        "            metadatas.append(metadata)\n",
        "            ids.append(mattress.get('id', str(uuid.uuid4())))\n",
        "\n",
        "        print(f\"ğŸ“Š ì²˜ë¦¬í•  ë§¤íŠ¸ë¦¬ìŠ¤ ê°œìˆ˜: {len(documents)}ê°œ\")\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±\n",
        "        print(\"ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
        "        embeddings = embedding_model.encode(documents)\n",
        "        print(f\"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ! í˜•íƒœ: {embeddings.shape}\")\n",
        "\n",
        "        # ChromaDBì— ì €ì¥\n",
        "        print(\"ğŸ’¾ ChromaDBì— ì €ì¥ ì¤‘...\")\n",
        "        collection.add(\n",
        "            documents=documents,\n",
        "            embeddings=embeddings.tolist(),\n",
        "            metadatas=metadatas,\n",
        "            ids=ids\n",
        "        )\n",
        "\n",
        "        print(\"âœ… ChromaDB ì €ì¥ ì™„ë£Œ!\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì„ë² ë”© ìƒì„±/ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
        "        return False\n",
        "\n",
        "# ë°ì´í„° ë²¡í„°í™” ì‹¤í–‰\n",
        "if 'mattress_data' in locals() or 'mattress_data' in globals():\n",
        "    success = create_mattress_embeddings(mattress_data)\n",
        "    if success:\n",
        "        # ì €ì¥ëœ ë°ì´í„° í™•ì¸\n",
        "        stored_count = collection.count()\n",
        "        print(f\"\\nğŸ“Š ChromaDB ì €ì¥ í™•ì¸:\")\n",
        "        print(f\"- ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {stored_count}ê°œ\")\n",
        "\n",
        "        # ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "        print(f\"\\nğŸ” ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:\")\n",
        "        test_query = \"í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒì—ê²Œ ì¢‹ì€ ë§¤íŠ¸ë¦¬ìŠ¤\"\n",
        "        test_results = collection.query(\n",
        "            query_texts=[test_query],\n",
        "            n_results=2\n",
        "        )\n",
        "\n",
        "        print(f\"ê²€ìƒ‰ì–´: '{test_query}'\")\n",
        "        for i, (doc, metadata) in enumerate(zip(test_results['documents'][0], test_results['metadatas'][0])):\n",
        "            print(f\"{i+1}. {metadata['name']} ({metadata['brand']})\")\n",
        "            print(f\"   ê°€ê²©: {metadata['price']:,}ì›\")\n",
        "            print(f\"   íƒ€ì…: {metadata['type']}\")\n",
        "    else:\n",
        "        print(\"âŒ ë²¡í„°í™” ì‹¤íŒ¨\")\n",
        "else:\n",
        "    print(\"âŒ mattress_dataê°€ ì—†ìŠµë‹ˆë‹¤. Phase 1ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpLzpKxBNLhp",
        "outputId": "9f3e64dc-3939-4f8d-8cbf-9844b74c21ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”„ ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° ë²¡í„°í™” ë° ì €ì¥...\n",
            "ğŸ“Š ì²˜ë¦¬í•  ë§¤íŠ¸ë¦¬ìŠ¤ ê°œìˆ˜: 1000ê°œ\n",
            "ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘...\n",
            "âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ! í˜•íƒœ: (1000, 384)\n",
            "ğŸ’¾ ChromaDBì— ì €ì¥ ì¤‘...\n",
            "âœ… ChromaDB ì €ì¥ ì™„ë£Œ!\n",
            "\n",
            "ğŸ“Š ChromaDB ì €ì¥ í™•ì¸:\n",
            "- ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: 1000ê°œ\n",
            "\n",
            "ğŸ” ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:\n",
            "ê²€ìƒ‰ì–´: 'í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒì—ê²Œ ì¢‹ì€ ë§¤íŠ¸ë¦¬ìŠ¤'\n",
            "1. IKEA HYLLESTAD ëª¨ë¸ 15 (IKEA)\n",
            "   ê°€ê²©: 344,153ì›\n",
            "   íƒ€ì…: ì ¤ë©”ëª¨ë¦¬í¼\n",
            "2. ACE HYBRID TECH ëª¨ë¸ 28 (ACE)\n",
            "   ê°€ê²©: 2,626,607ì›\n",
            "   íƒ€ì…: ë©”ëª¨ë¦¬í¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) RAG ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„"
      ],
      "metadata": {
        "id": "ZRTraX5FNOVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. RAG ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„\n",
        "print(\"\\nğŸ”§ RAG ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„...\")\n",
        "\n",
        "def search_similar_mattresses(query: str, n_results: int = 3) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    ì‚¬ìš©ì ì¿¼ë¦¬ì— ëŒ€í•´ ìœ ì‚¬í•œ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ê²€ìƒ‰\n",
        "\n",
        "    Args:\n",
        "        query: ì‚¬ìš©ìì˜ ê²€ìƒ‰ ì¿¼ë¦¬\n",
        "        n_results: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜\n",
        "\n",
        "    Returns:\n",
        "        ìœ ì‚¬í•œ ë§¤íŠ¸ë¦¬ìŠ¤ ë¦¬ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ChromaDBì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
        "        results = collection.query(\n",
        "            query_texts=[query],\n",
        "            n_results=n_results\n",
        "        )\n",
        "\n",
        "        # ê²°ê³¼ í¬ë§·íŒ…\n",
        "        similar_mattresses = []\n",
        "\n",
        "        for i in range(len(results['ids'][0])):\n",
        "            mattress_info = {\n",
        "                'id': results['ids'][0][i],\n",
        "                'name': results['metadatas'][0][i]['name'],\n",
        "                'brand': results['metadatas'][0][i]['brand'],\n",
        "                'type': results['metadatas'][0][i]['type'],\n",
        "                'price': results['metadatas'][0][i]['price'],\n",
        "                'firmness': results['metadatas'][0][i]['firmness'],\n",
        "                'similarity_score': 1 - results['distances'][0][i],  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜\n",
        "                'content': results['documents'][0][i]\n",
        "            }\n",
        "            similar_mattresses.append(mattress_info)\n",
        "\n",
        "        return similar_mattresses\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
        "        return []\n",
        "\n",
        "print(\"âœ… RAG ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UcqLKrkNRE8",
        "outputId": "a7de5eb0-e2fa-4cd4-ba6e-59faa59d0731"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ RAG ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„...\n",
            "âœ… RAG ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "vJvVnfg7NTXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
        "print(\"\\nğŸ§ª RAG ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸...\")\n",
        "\n",
        "test_queries = [\n",
        "    \"í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒì„ ìœ„í•œ ë§¤íŠ¸ë¦¬ìŠ¤\",\n",
        "    \"ì˜ˆì‚° 30ë§Œì› ì´í•˜ ë§¤íŠ¸ë¦¬ìŠ¤\",\n",
        "    \"ë”ìœ„ ë§ì´ íƒ€ëŠ” ì‚¬ëŒìš© ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤\",\n",
        "    \"ì»¤í”Œì´ ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ë§¤íŠ¸ë¦¬ìŠ¤\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'\")\n",
        "    results = search_similar_mattresses(query, n_results=2)\n",
        "\n",
        "    if results:\n",
        "        for i, result in enumerate(results):\n",
        "            print(f\"  {i+1}. {result['name']} ({result['brand']})\")\n",
        "            print(f\"     ğŸ’° ê°€ê²©: {result['price']:,}ì›\")\n",
        "            print(f\"     ğŸ›ï¸ íƒ€ì…: {result['type']}\")\n",
        "            print(f\"     ğŸ“Š ìœ ì‚¬ë„: {result['similarity_score']:.3f}\")\n",
        "    else:\n",
        "        print(\"  âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"âœ… Phase 2 ì™„ë£Œ!\")\n",
        "print(\"ğŸ¯ ë‹¬ì„± ë‚´ìš©:\")\n",
        "print(\"- ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•\")\n",
        "print(\"- sentence-transformers ì„ë² ë”© ëª¨ë¸ ì ìš©\")\n",
        "print(\"- ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ ì‹œìŠ¤í…œ\")\n",
        "print(\"- RAG ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸\")\n",
        "print(\"\\në‹¤ìŒ ë‹¨ê³„: Phase 3 - AI Agent í•µì‹¬ ë¡œì§ (Function Calling)\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZZp_ZKCIcY-",
        "outputId": "576470ca-1c54-46cf-9de9-51eb445468ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§ª RAG ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸...\n",
            "\n",
            "ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: 'í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒì„ ìœ„í•œ ë§¤íŠ¸ë¦¬ìŠ¤'\n",
            "  1. IKEA MORGEDAL ëª¨ë¸ 39 (IKEA)\n",
            "     ğŸ’° ê°€ê²©: 2,304,046ì›\n",
            "     ğŸ›ï¸ íƒ€ì…: ì ¤ë©”ëª¨ë¦¬í¼\n",
            "     ğŸ“Š ìœ ì‚¬ë„: -0.159\n",
            "  2. IKEA HYLLESTAD ëª¨ë¸ 15 (IKEA)\n",
            "     ğŸ’° ê°€ê²©: 344,153ì›\n",
            "     ğŸ›ï¸ íƒ€ì…: ì ¤ë©”ëª¨ë¦¬í¼\n",
            "     ğŸ“Š ìœ ì‚¬ë„: -0.162\n",
            "\n",
            "ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: 'ì˜ˆì‚° 30ë§Œì› ì´í•˜ ë§¤íŠ¸ë¦¬ìŠ¤'\n",
            "  1. IKEA HYLLESTAD ëª¨ë¸ 15 (IKEA)\n",
            "     ğŸ’° ê°€ê²©: 344,153ì›\n",
            "     ğŸ›ï¸ íƒ€ì…: ì ¤ë©”ëª¨ë¦¬í¼\n",
            "     ğŸ“Š ìœ ì‚¬ë„: -0.230\n",
            "  2. IKEA MORGEDAL ëª¨ë¸ 39 (IKEA)\n",
            "     ğŸ’° ê°€ê²©: 2,304,046ì›\n",
            "     ğŸ›ï¸ íƒ€ì…: ì ¤ë©”ëª¨ë¦¬í¼\n",
            "     ğŸ“Š ìœ ì‚¬ë„: -0.231\n",
            "\n",
            "ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: 'ë”ìœ„ ë§ì´ íƒ€ëŠ” ì‚¬ëŒìš© ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤'\n",
            "  1. IKEA MORGEDAL ëª¨ë¸ 39 (IKEA)\n",
            "     ğŸ’° ê°€ê²©: 2,304,046ì›\n",
            "     ğŸ›ï¸ íƒ€ì…: ì ¤ë©”ëª¨ë¦¬í¼\n",
            "     ğŸ“Š ìœ ì‚¬ë„: -0.138\n",
            "  2. IKEA HYLLESTAD ëª¨ë¸ 15 (IKEA)\n",
            "     ğŸ’° ê°€ê²©: 344,153ì›\n",
            "     ğŸ›ï¸ íƒ€ì…: ì ¤ë©”ëª¨ë¦¬í¼\n",
            "     ğŸ“Š ìœ ì‚¬ë„: -0.142\n",
            "\n",
            "ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: 'ì»¤í”Œì´ ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ë§¤íŠ¸ë¦¬ìŠ¤'\n",
            "  1. IKEA HYLLESTAD ëª¨ë¸ 60 (IKEA)\n",
            "     ğŸ’° ê°€ê²©: 1,750,752ì›\n",
            "     ğŸ›ï¸ íƒ€ì…: í•˜ì´ë¸Œë¦¬ë“œ\n",
            "     ğŸ“Š ìœ ì‚¬ë„: 0.051\n",
            "  2. IKEA HYLLESTAD ëª¨ë¸ 63 (IKEA)\n",
            "     ğŸ’° ê°€ê²©: 2,282,629ì›\n",
            "     ğŸ›ï¸ íƒ€ì…: ìŠ¤í”„ë§\n",
            "     ğŸ“Š ìœ ì‚¬ë„: 0.035\n",
            "\n",
            "==================================================\n",
            "âœ… Phase 2 ì™„ë£Œ!\n",
            "ğŸ¯ ë‹¬ì„± ë‚´ìš©:\n",
            "- ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•\n",
            "- sentence-transformers ì„ë² ë”© ëª¨ë¸ ì ìš©\n",
            "- ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ ì‹œìŠ¤í…œ\n",
            "- RAG ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸\n",
            "\n",
            "ë‹¤ìŒ ë‹¨ê³„: Phase 3 - AI Agent í•µì‹¬ ë¡œì§ (Function Calling)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Function Calling & Prompt Engineering"
      ],
      "metadata": {
        "id": "TE85LkD9Nvp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Hugging Face ëª¨ë¸ ì„¤ì¹˜ ë° ì„¤ì •"
      ],
      "metadata": {
        "id": "MeKpYslAOHoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 3: AI Agent í•µì‹¬ ë¡œì§ - Function Calling + Prompt Engineering\n",
        "\n",
        "# 1. Hugging Face ëª¨ë¸ ì„¤ì¹˜ ë° ì„¤ì •\n",
        "!pip install transformers torch accelerate -q\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import json\n",
        "from typing import Dict, List, Any, Optional\n",
        "import re\n",
        "\n",
        "print(\"âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_GuRfSnOL5O",
        "outputId": "0a1a5a9d-34de-4e20-f8ca-7d3941814b33"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) LLM ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ì§€ì›)"
      ],
      "metadata": {
        "id": "9SGLa9WVOOCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. LLM ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ì§€ì›)\n",
        "def load_korean_llm():\n",
        "    \"\"\"í•œêµ­ì–´ ì§€ì› LLM ëª¨ë¸ ë¡œë“œ\"\"\"\n",
        "    try:\n",
        "        # ê²½ëŸ‰ í•œêµ­ì–´ ëª¨ë¸ ì‹œë„\n",
        "        model_name = \"microsoft/DialoGPT-medium\"  # ì˜ì–´ ê¸°ë°˜ì´ì§€ë§Œ ì•ˆì •ì \n",
        "\n",
        "        print(f\"ëª¨ë¸ ë¡œë“œ ì‹œë„: {model_name}\")\n",
        "\n",
        "        # GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPU, ì•„ë‹ˆë©´ CPU\n",
        "        device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
        "        generator = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model_name,\n",
        "            device=device,\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            pad_token_id=50256\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… LLM ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
        "        print(f\"ğŸ’» ì‚¬ìš© ë””ë°”ì´ìŠ¤: {'GPU' if device == 0 else 'CPU'}\")\n",
        "\n",
        "        return generator\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "        print(\"ğŸ’¡ ëŒ€ì•ˆ: í…œí”Œë¦¿ ê¸°ë°˜ ì‘ë‹µ ì‹œìŠ¤í…œ ì‚¬ìš©\")\n",
        "        return None\n",
        "\n",
        "# ëª¨ë¸ ë¡œë“œ ì‹¤í–‰\n",
        "llm_generator = load_korean_llm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzkGAtAVOQdY",
        "outputId": "df5ebb89-bc90-46d2-ebc5-c8d2a8ed6213"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª¨ë¸ ë¡œë“œ ì‹œë„: microsoft/DialoGPT-medium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… LLM ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\n",
            "ğŸ’» ì‚¬ìš© ë””ë°”ì´ìŠ¤: CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Function Calling ì‹œìŠ¤í…œ êµ¬í˜„"
      ],
      "metadata": {
        "id": "NxUGMWqTOS7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from typing import Dict, List\n",
        "\n",
        "# 3. Function Calling ì‹œìŠ¤í…œ êµ¬í˜„\n",
        "class MattressFunctionCalling:\n",
        "    \"\"\"ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œì„ ìœ„í•œ Function Calling ì‹œìŠ¤í…œ\"\"\"\n",
        "\n",
        "    def __init__(self, search_function):\n",
        "        self.search_function = search_function\n",
        "        self.user_preferences = {}\n",
        "\n",
        "        # ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë“¤ ì •ì˜\n",
        "        self.available_functions = {\n",
        "            \"collect_user_preferences\": self.collect_user_preferences,\n",
        "            \"search_mattresses\": self.search_mattresses,\n",
        "            \"calculate_recommendation_score\": self.calculate_recommendation_score,\n",
        "            \"generate_recommendation\": self.generate_recommendation,\n",
        "            \"get_budget_filtered_mattresses\": self.get_budget_filtered_mattresses\n",
        "        }\n",
        "\n",
        "    def collect_user_preferences(self, **kwargs) -> Dict:\n",
        "        \"\"\"ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì„ í˜¸ë„ ì •ë³´ë¥¼ ìë™ ì¶”ì¶œí•˜ì—¬ ìˆ˜ì§‘\"\"\"\n",
        "        print(\"ğŸ¯ Function Call: collect_user_preferences\")\n",
        "\n",
        "        user_question = kwargs.get(\"user_question\", \"\")\n",
        "\n",
        "        # ë‚´ë¶€ì—ì„œ ìì—°ì–´ ê¸°ë°˜ íŒŒì‹± ì‹¤í–‰\n",
        "\n",
        "        preferences = {}\n",
        "\n",
        "       # ì˜ˆì‚° ì¶”ì¶œ (e.g. \"40ë§Œì›\", \"30ë§Œ ì› ì´í•˜\")\n",
        "        budget_match = re.search(r'(\\d+)\\s*ë§Œ\\s*ì›', user_question)\n",
        "        if budget_match:\n",
        "           preferences[\"budget\"] = int(budget_match.group(1)) * 10000\n",
        "\n",
        "        # ìˆ˜ë©´ ìì„¸\n",
        "        if \"ì˜†ìœ¼ë¡œ\" in user_question or \"ì¸¡ë©´\" in user_question:\n",
        "            preferences[\"sleep_position\"] = \"side\"\n",
        "        elif \"ì—ë“œë ¤\" in user_question:\n",
        "            preferences[\"sleep_position\"] = \"stomach\"\n",
        "        elif \"ë°”ë¡œ ëˆ„ì›Œ\" in user_question or \"ë“±ìœ¼ë¡œ\" in user_question:\n",
        "            preferences[\"sleep_position\"] = \"back\"\n",
        "\n",
        "       # ì²´í˜•\n",
        "        if \"ë§ˆë¥¸\" in user_question or \"ê°€ë²¼ìš´\" in user_question:\n",
        "            preferences[\"body_weight\"] = \"light\"\n",
        "        elif \"í‰ê· \" in user_question:\n",
        "             preferences[\"body_weight\"] = \"average\"\n",
        "        elif \"ë¬´ê±°ìš´\" in user_question or \"ì²´ê²© í°\" in user_question:\n",
        "            preferences[\"body_weight\"] = \"heavy\"\n",
        "\n",
        "        # ê±´ê°• ì´ìŠˆ\n",
        "        health_issues = []\n",
        "        if \"í—ˆë¦¬\" in user_question or \"ìš”í†µ\" in user_question:\n",
        "            health_issues.append(\"back_pain\")\n",
        "        preferences[\"health_issues\"] = health_issues\n",
        "\n",
        "       # ì•Œë ˆë¥´ê¸°\n",
        "        if \"ì•Œë ˆë¥´ê¸°\" in user_question or \"í•­ê· \" in user_question or \"ì²œì—°ì†Œì¬\" in user_question:\n",
        "            preferences[\"allergies\"] = True\n",
        "\n",
        "        # ì²´ì˜¨ ë¯¼ê°ë„\n",
        "        if \"ë”ìœ„\" in user_question or \"ì—´ëŒ€ì•¼\" in user_question or \"ë•€\" in user_question:\n",
        "            preferences[\"temperature_preference\"] = \"cool\"\n",
        "\n",
        "        # ì»¤í”Œ ì—¬ë¶€\n",
        "        if \"ì»¤í”Œ\" in user_question or \"2ëª…ì´\" in user_question:\n",
        "             preferences[\"partner\"] = True\n",
        "\n",
        "        # ì„ í˜¸ ê²½ë„\n",
        "        if \"ë”±ë”±í•œ\" in user_question or \"ë‹¨ë‹¨í•œ\" in user_question:\n",
        "             preferences[\"firmness_preference\"] = \"firm\"\n",
        "        elif \"ë¶€ë“œëŸ¬ìš´\" in user_question or \"í­ì‹ í•œ\" in user_question:\n",
        "             preferences[\"firmness_preference\"] = \"soft\"\n",
        "\n",
        "        # ê¸°ì¡´ êµ¬ì¡° ìœ ì§€: selfì— ì—…ë°ì´íŠ¸\n",
        "        self.user_preferences.update(preferences)\n",
        "\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"ì‚¬ìš©ì ì„ í˜¸ë„ ìˆ˜ì§‘ ì™„ë£Œ\",\n",
        "            \"preferences\": preferences\n",
        "       }\n",
        "\n",
        "    def search_mattresses(self, query: str, n_results: int = 5) -> List[Dict]:\n",
        "        \"\"\"RAG ì‹œìŠ¤í…œì„ í†µí•œ ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰\"\"\"\n",
        "        print(f\"ğŸ” Function Call: search_mattresses('{query}')\")\n",
        "\n",
        "        if self.search_function:\n",
        "            results = self.search_function(query, n_results)\n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"query\": query,\n",
        "                \"results\": results,\n",
        "                \"count\": len(results)\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"message\": \"ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"\n",
        "            }\n",
        "\n",
        "    def get_budget_filtered_mattresses(self, budget: int) -> List[Dict]:\n",
        "        \"\"\"ì˜ˆì‚° ê¸°ë°˜ ë§¤íŠ¸ë¦¬ìŠ¤ í•„í„°ë§\"\"\"\n",
        "        print(f\"ğŸ’° Function Call: get_budget_filtered_mattresses({budget:,}ì›)\")\n",
        "\n",
        "        # ì˜ˆì‚°ì— ë§ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰\n",
        "        query = f\"ê°€ê²© {budget:,}ì› ì´í•˜ ë§¤íŠ¸ë¦¬ìŠ¤\"\n",
        "        search_results = self.search_function(query, n_results=10)\n",
        "\n",
        "        # ì˜ˆì‚° í•„í„°ë§\n",
        "        filtered = [m for m in search_results if m.get('price', 0) <= budget]\n",
        "\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"budget\": budget,\n",
        "            \"results\": filtered,\n",
        "            \"count\": len(filtered)\n",
        "        }\n",
        "\n",
        "    def calculate_recommendation_score(self, mattress: Dict) -> float:\n",
        "        \"\"\"ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ ì ìˆ˜ ê³„ì‚°\"\"\"\n",
        "        print(f\"ğŸ“Š Function Call: calculate_recommendation_score\")\n",
        "\n",
        "        score = 0.0\n",
        "        max_score = 0.0\n",
        "\n",
        "        # ì˜ˆì‚° ì ìˆ˜ (30%)\n",
        "        max_score += 30\n",
        "        user_budget = self.user_preferences.get(\"budget\", 0)\n",
        "        mattress_price = mattress.get(\"price\", 0)\n",
        "\n",
        "        if user_budget > 0 and mattress_price <= user_budget:\n",
        "            score += 30\n",
        "        elif user_budget > 0:\n",
        "            # ì˜ˆì‚° ì´ˆê³¼ ì‹œ ê°ì \n",
        "            over_ratio = (mattress_price - user_budget) / user_budget\n",
        "            score += max(0, 30 - (over_ratio * 30))\n",
        "\n",
        "        # ìˆ˜ë©´ìì„¸ ì ìˆ˜ (25%)\n",
        "        max_score += 25\n",
        "        sleep_position = self.user_preferences.get(\"sleep_position\", \"\").lower()\n",
        "        firmness = mattress.get(\"firmness\", \"\").lower()\n",
        "\n",
        "        if sleep_position == \"side\" and \"ì†Œí”„íŠ¸\" in firmness:\n",
        "            score += 25\n",
        "        elif sleep_position == \"back\" and \"ë¯¸ë””ì›€\" in firmness:\n",
        "            score += 25\n",
        "        elif sleep_position == \"stomach\" and (\"íŒ\" in firmness or \"ë”±ë”±\" in firmness):\n",
        "            score += 25\n",
        "        else:\n",
        "            score += 10  # ê¸°ë³¸ ì ìˆ˜\n",
        "\n",
        "        # ê±´ê°• ë¬¸ì œ ì ìˆ˜ (25%)\n",
        "        max_score += 25\n",
        "        health_issues = self.user_preferences.get(\"health_issues\", [])\n",
        "        mattress_type = mattress.get(\"type\", \"\").lower()\n",
        "\n",
        "        if \"í—ˆë¦¬í†µì¦\" in health_issues and \"ë©”ëª¨ë¦¬í¼\" in mattress_type:\n",
        "            score += 25\n",
        "        elif \"ê´€ì ˆì—¼\" in health_issues and (\"ë¼í…ìŠ¤\" in mattress_type or \"ë©”ëª¨ë¦¬í¼\" in mattress_type):\n",
        "            score += 20\n",
        "        else:\n",
        "            score += 10\n",
        "\n",
        "        # ì˜¨ë„ ì„ í˜¸ë„ ì ìˆ˜ (20%)\n",
        "        max_score += 20\n",
        "        temp_pref = self.user_preferences.get(\"temperature_preference\", \"\").lower()\n",
        "\n",
        "        if \"ì‹œì›í•¨\" in temp_pref and (\"ì ¤\" in mattress_type or \"í•˜ì´ë¸Œë¦¬ë“œ\" in mattress_type):\n",
        "            score += 20\n",
        "        elif \"ë”°ëœ»í•¨\" in temp_pref and \"ë©”ëª¨ë¦¬í¼\" in mattress_type:\n",
        "            score += 20\n",
        "        else:\n",
        "            score += 10\n",
        "\n",
        "        # ì•Œë ˆë¥´ê¸° ê´€ë ¨ ì ìˆ˜ (ì¶”ê°€ë¡œ 10ì  êµ¬ì„± ê°€ëŠ¥)\n",
        "        max_score += 10\n",
        "        if self.user_preferences.get(\"allergies\", False):\n",
        "           if any(\"í•­ê· \" in f or \"ì²œì—°\" in f for f in mattress.get(\"features\", [])):\n",
        "              score += 10\n",
        "           else:\n",
        "              score += 5\n",
        "\n",
        "        # ì •ê·œí™”ëœ ì ìˆ˜ ë°˜í™˜ (0-1)\n",
        "        normalized_score = score / max_score if max_score > 0 else 0\n",
        "\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"score\": normalized_score,\n",
        "            \"raw_score\": score,\n",
        "            \"max_score\": max_score,\n",
        "            \"details\": {\n",
        "                \"budget_score\": min(30, score),\n",
        "                \"sleep_position_score\": \"calculated\",\n",
        "                \"health_score\": \"calculated\",\n",
        "                \"temperature_score\": \"calculated\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_recommendation(self, top_mattresses: List[Dict]) -> Dict:\n",
        "        \"\"\"ìµœì¢… ì¶”ì²œ ìƒì„±\"\"\"\n",
        "        print(\"ğŸ¯ Function Call: generate_recommendation\")\n",
        "\n",
        "        if not top_mattresses:\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"message\": \"ì¶”ì²œí•  ë§¤íŠ¸ë¦¬ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤\"\n",
        "            }\n",
        "\n",
        "        # ìƒìœ„ 3ê°œ ë§¤íŠ¸ë¦¬ìŠ¤ ì„ íƒ\n",
        "        recommendations = top_mattresses[:3]\n",
        "\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"recommendations\": recommendations,\n",
        "            \"total_candidates\": len(top_mattresses),\n",
        "            \"user_preferences\": self.user_preferences\n",
        "        }\n",
        "\n",
        "# Function Calling ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
        "if 'search_similar_mattresses' in locals():\n",
        "    function_caller = MattressFunctionCalling(search_similar_mattresses)\n",
        "    print(\"âœ… Function Calling ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
        "else:\n",
        "    print(\"âŒ RAG ê²€ìƒ‰ í•¨ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. Phase 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig_5YErhIkXS",
        "outputId": "c75d9857-9068-48e6-e4fc-c4f67f46609a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Function Calling ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) ê³ ê¸‰ Prompt Engineering êµ¬í˜„"
      ],
      "metadata": {
        "id": "vD3muNo8OgOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. ê³ ê¸‰ Prompt Engineering êµ¬í˜„\n",
        "class AdvancedPromptEngine:\n",
        "    \"\"\"ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì‹œìŠ¤í…œ\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.system_prompt = self._create_system_prompt()\n",
        "\n",
        "    def _create_system_prompt(self) -> str:\n",
        "        \"\"\"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (Role-based + CoT)\"\"\"\n",
        "        return \"\"\"\n",
        "ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "ê³ ê°ì˜ ìˆ˜ë©´ íŒ¨í„´, ì²´í˜•, ê±´ê°• ìƒíƒœ, ì˜ˆì‚°ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬\n",
        "ìµœì ì˜ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì¶”ì²œí•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì—­í• ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì¶”ì²œ ê³¼ì •ì€ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¼ ì§„í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "1. ê³ ê° ë¶„ì„: ìˆ˜ë©´ìì„¸, ì²´ì¤‘, ê±´ê°• ë¬¸ì œ, ì˜ˆì‚° íŒŒì•…\n",
        "2. ì¡°ê±´ ë§¤ì¹­: ê³ ê° ì¡°ê±´ì— ë§ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ íƒ€ì… ê²°ì •\n",
        "3. ì œí’ˆ ê²€ìƒ‰: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì í•©í•œ ì œí’ˆ ì°¾ê¸°\n",
        "4. ì ìˆ˜ ê³„ì‚°: ê° ì œí’ˆì˜ ì í•©ë„ ì ìˆ˜ ì‚°ì¶œ\n",
        "5. ìµœì¢… ì¶”ì²œ: ìƒìœ„ 3ê°œ ì œí’ˆì„ ì´ìœ ì™€ í•¨ê»˜ ì œì‹œ\n",
        "\n",
        "í•­ìƒ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•˜ë©°,\n",
        "ê³ ê°ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "    def create_user_analysis_prompt(self, user_input: str) -> str:\n",
        "        \"\"\"ì‚¬ìš©ì ì…ë ¥ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ (Few-shot Learning)\"\"\"\n",
        "        return f\"\"\"\n",
        "ë‹¤ìŒì€ ê³ ê°ì˜ ë§¤íŠ¸ë¦¬ìŠ¤ êµ¬ë§¤ ìƒë‹´ ë‚´ìš©ì…ë‹ˆë‹¤:\n",
        "\"{user_input}\"\n",
        "\n",
        "ì´ì „ ìƒë‹´ ì‚¬ë¡€ë“¤ì„ ì°¸ê³ í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”:\n",
        "\n",
        "ì‚¬ë¡€ 1:\n",
        "ì…ë ¥: \"ì ìë¦¬ì—ì„œ ìì£¼ ë’¤ì²™ì´ê³ , í—ˆë¦¬ê°€ ì•„í”ˆ í¸ì´ì—ìš”. ì˜ˆì‚°ì€ 50ë§Œì› ì •ë„ì…ë‹ˆë‹¤.\"\n",
        "ë¶„ì„: ìˆ˜ë©´ìì„¸=ì¸¡ë©´ìˆ˜ë©´, ê±´ê°•ë¬¸ì œ=í—ˆë¦¬í†µì¦, ì˜ˆì‚°=500000, ì›€ì§ì„=ë§ìŒ\n",
        "\n",
        "ì‚¬ë¡€ 2:\n",
        "ì…ë ¥: \"ë”ìœ„ë¥¼ ë§ì´ íƒ€ì„œ ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”. ë‹¨ë‹¨í•œ ê±¸ ì¢‹ì•„í•´ìš”.\"\n",
        "ë¶„ì„: ì˜¨ë„ì„ í˜¸=ì‹œì›í•¨, ë‹¨ë‹¨í•¨ì„ í˜¸=íŒ, ì˜ˆì‚°=ë¯¸ì§€ì •\n",
        "\n",
        "í˜„ì¬ ê³ ê° ë¶„ì„:\n",
        "ìˆ˜ë©´ìì„¸:\n",
        "ì²´ì¤‘:\n",
        "ê±´ê°•ë¬¸ì œ:\n",
        "ì˜ˆì‚°:\n",
        "ì˜¨ë„ì„ í˜¸:\n",
        "ë‹¨ë‹¨í•¨ì„ í˜¸:\n",
        "íŠ¹ì´ì‚¬í•­:\n",
        "\n",
        "ìœ„ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "    def create_recommendation_prompt(self, user_prefs: Dict, mattresses: List[Dict]) -> str:\n",
        "        \"\"\"ì¶”ì²œ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ (Chain of Thought)\"\"\"\n",
        "        return f\"\"\"\n",
        "ê³ ê° ì •ë³´:\n",
        "- ìˆ˜ë©´ìì„¸: {user_prefs.get('sleep_position', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
        "- ì˜ˆì‚°: {user_prefs.get('budget', 'ì•Œ ìˆ˜ ì—†ìŒ'):,}ì›\n",
        "- ê±´ê°•ë¬¸ì œ: {', '.join(user_prefs.get('health_issues', ['ì—†ìŒ']))}\n",
        "- ì˜¨ë„ì„ í˜¸: {user_prefs.get('temperature_preference', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n",
        "\n",
        "í›„ë³´ ë§¤íŠ¸ë¦¬ìŠ¤ë“¤:\n",
        "{self._format_mattresses_for_prompt(mattresses)}\n",
        "\n",
        "ë‹¨ê³„ë³„ ì¶”ì²œ ê³¼ì •:\n",
        "\n",
        "1ë‹¨ê³„ - ê³ ê° ìš”êµ¬ì‚¬í•­ ìš°ì„ ìˆœìœ„:\n",
        "   ê°€ì¥ ì¤‘ìš”í•œ ìš”êµ¬ì‚¬í•­ì€?\n",
        "\n",
        "2ë‹¨ê³„ - ë§¤íŠ¸ë¦¬ìŠ¤ë³„ ì í•©ë„ ë¶„ì„:\n",
        "   ê° ë§¤íŠ¸ë¦¬ìŠ¤ê°€ ê³ ê°ì—ê²Œ ì í•©í•œ ì´ìœ ëŠ”?\n",
        "\n",
        "3ë‹¨ê³„ - ìµœì¢… ì¶”ì²œ (ìƒìœ„ 3ê°œ):\n",
        "   1ìˆœìœ„: [ì œí’ˆëª…] - [ì¶”ì²œ ì´ìœ ]\n",
        "   2ìˆœìœ„: [ì œí’ˆëª…] - [ì¶”ì²œ ì´ìœ ]\n",
        "   3ìˆœìœ„: [ì œí’ˆëª…] - [ì¶”ì²œ ì´ìœ ]\n",
        "\n",
        "4ë‹¨ê³„ - ì£¼ì˜ì‚¬í•­ ë° ì¡°ì–¸:\n",
        "   ê³ ê°ì´ ì£¼ì˜í•´ì•¼ í•  ì ì€?\n",
        "\n",
        "ìœ„ í˜•ì‹ìœ¼ë¡œ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ê³  ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "    def _format_mattresses_for_prompt(self, mattresses: List[Dict]) -> str:\n",
        "        \"\"\"ë§¤íŠ¸ë¦¬ìŠ¤ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…\"\"\"\n",
        "        formatted = \"\"\n",
        "        for i, m in enumerate(mattresses, 1):\n",
        "            formatted += f\"\"\"\n",
        "{i}. {m.get('name', 'Unknown')} ({m.get('brand', 'Unknown')})\n",
        "   - íƒ€ì…: {m.get('type', 'Unknown')}\n",
        "   - ê°€ê²©: {m.get('price', 0):,}ì›\n",
        "   - ë‹¨ë‹¨í•¨: {m.get('firmness', 'Unknown')}\n",
        "   - ìœ ì‚¬ë„: {m.get('similarity_score', 0):.3f}\n",
        "\"\"\"\n",
        "        return formatted.strip()\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ ì—”ì§„ ì´ˆê¸°í™”\n",
        "prompt_engine = AdvancedPromptEngine()\n",
        "print(\"âœ… ê³ ê¸‰ Prompt Engineering ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYUnYCEgIkU5",
        "outputId": "ce2f9bc7-fb2f-4bc6-96d1-6f36263f333b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ê³ ê¸‰ Prompt Engineering ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) AI Agent ë©”ì¸ í´ë˜ìŠ¤ êµ¬í˜„"
      ],
      "metadata": {
        "id": "uUzQuf4aOkpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. AI Agent ë©”ì¸ í´ë˜ìŠ¤ êµ¬í˜„\n",
        "class MattressRecommendationAgent:\n",
        "    \"\"\"ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ AI Agent\"\"\"\n",
        "\n",
        "    def __init__(self, function_caller, prompt_engine, llm_generator=None):\n",
        "        self.function_caller = function_caller\n",
        "        self.prompt_engine = prompt_engine\n",
        "        self.llm_generator = llm_generator\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def analyze_user_input(self, user_input: str) -> Dict:\n",
        "        \"\"\"ì‚¬ìš©ì ì…ë ¥ ë¶„ì„ ë° ì„ í˜¸ë„ ì¶”ì¶œ\"\"\"\n",
        "        print(f\"ğŸ” ì‚¬ìš©ì ì…ë ¥ ë¶„ì„: '{user_input}'\")\n",
        "\n",
        "        # ê·œì¹™ ê¸°ë°˜ ë¶„ì„ (LLM ëŒ€ì•ˆ)\n",
        "        preferences = {\n",
        "            \"sleep_position\": \"\",\n",
        "            \"body_weight\": \"\",\n",
        "            \"budget\": 0,\n",
        "            \"health_issues\": [],\n",
        "            \"temperature_preference\": \"\",\n",
        "            \"partner\": False,\n",
        "            \"firmness_preference\": \"\"\n",
        "        }\n",
        "\n",
        "        # ì˜ˆì‚° ì¶”ì¶œ\n",
        "        budget_pattern = r'(\\d+)ë§Œì›|(\\d+)ì›'\n",
        "        budget_match = re.search(budget_pattern, user_input)\n",
        "        if budget_match:\n",
        "            if budget_match.group(1):  # ë§Œì› ë‹¨ìœ„\n",
        "                preferences[\"budget\"] = int(budget_match.group(1)) * 10000\n",
        "            elif budget_match.group(2):  # ì› ë‹¨ìœ„\n",
        "                preferences[\"budget\"] = int(budget_match.group(2))\n",
        "\n",
        "        # ê±´ê°• ë¬¸ì œ ì¶”ì¶œ\n",
        "        health_keywords = {\n",
        "            \"í—ˆë¦¬\": \"í—ˆë¦¬í†µì¦\",\n",
        "            \"ê´€ì ˆ\": \"ê´€ì ˆì—¼\",\n",
        "            \"ëª©\": \"ëª©í†µì¦\",\n",
        "            \"ì–´ê¹¨\": \"ì–´ê¹¨í†µì¦\"\n",
        "        }\n",
        "\n",
        "        for keyword, issue in health_keywords.items():\n",
        "            if keyword in user_input:\n",
        "                preferences[\"health_issues\"].append(issue)\n",
        "\n",
        "        # ì˜¨ë„ ì„ í˜¸ë„\n",
        "        if any(word in user_input for word in [\"ë”ìœ„\", \"ì‹œì›\", \"ì°¨ê°€\"]):\n",
        "            preferences[\"temperature_preference\"] = \"ì‹œì›í•¨\"\n",
        "        elif any(word in user_input for word in [\"ì¶”ìœ„\", \"ë”°ëœ»\", \"ì˜¨\"]):\n",
        "            preferences[\"temperature_preference\"] = \"ë”°ëœ»í•¨\"\n",
        "\n",
        "        # ìˆ˜ë©´ìì„¸\n",
        "        if any(word in user_input for word in [\"ì˜†\", \"ì¸¡ë©´\"]):\n",
        "            preferences[\"sleep_position\"] = \"side\"\n",
        "        elif any(word in user_input for word in [\"ë“±\", \"ë°˜ë“¯\"]):\n",
        "            preferences[\"sleep_position\"] = \"back\"\n",
        "        elif any(word in user_input for word in [\"ì—ë“œë ¤\", \"ë°°\"]):\n",
        "            preferences[\"sleep_position\"] = \"stomach\"\n",
        "\n",
        "        # ë‹¨ë‹¨í•¨ ì„ í˜¸ë„\n",
        "        if any(word in user_input for word in [\"ë”±ë”±\", \"ë‹¨ë‹¨\", \"íŒ\"]):\n",
        "            preferences[\"firmness_preference\"] = \"íŒ\"\n",
        "        elif any(word in user_input for word in [\"ë¶€ë“œëŸ¬\", \"ì†Œí”„íŠ¸\"]):\n",
        "            preferences[\"firmness_preference\"] = \"ì†Œí”„íŠ¸\"\n",
        "\n",
        "        # ì»¤í”Œ ì—¬ë¶€\n",
        "        if any(word in user_input for word in [\"ì»¤í”Œ\", \"ë‘˜ì´\", \"ê°™ì´\", \"íŒŒíŠ¸ë„ˆ\"]):\n",
        "            preferences[\"partner\"] = True\n",
        "\n",
        "        return preferences\n",
        "\n",
        "    def recommend_mattresses(self, user_input: str) -> Dict:\n",
        "        \"\"\"ë©”ì¸ ì¶”ì²œ ë¡œì§\"\"\"\n",
        "        print(f\"\\nğŸ¯ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘\")\n",
        "        print(f\"ì‚¬ìš©ì ì…ë ¥: '{user_input}'\")\n",
        "\n",
        "        # 1. ì‚¬ìš©ì ì„ í˜¸ë„ ë¶„ì„\n",
        "        user_prefs = self.analyze_user_input(user_input)\n",
        "        print(f\"ğŸ“Š ë¶„ì„ëœ ì„ í˜¸ë„: {user_prefs}\")\n",
        "\n",
        "        # 2. Function Call: ì„ í˜¸ë„ ì €ì¥\n",
        "        self.function_caller.collect_user_preferences(**user_prefs)\n",
        "\n",
        "        # 3. Function Call: ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰\n",
        "        search_query = self._create_search_query(user_prefs, user_input)\n",
        "        search_results = self.function_caller.search_mattresses(search_query, n_results=8)\n",
        "\n",
        "        if search_results[\"status\"] != \"success\":\n",
        "            return {\"error\": \"ê²€ìƒ‰ ì‹¤íŒ¨\"}\n",
        "\n",
        "        mattresses = search_results[\"results\"]\n",
        "\n",
        "        # 4. Function Call: ì ìˆ˜ ê³„ì‚°\n",
        "        scored_mattresses = []\n",
        "        for mattress in mattresses:\n",
        "            score_result = self.function_caller.calculate_recommendation_score(mattress)\n",
        "            if score_result[\"status\"] == \"success\":\n",
        "                mattress[\"recommendation_score\"] = score_result[\"score\"]\n",
        "                scored_mattresses.append(mattress)\n",
        "\n",
        "        # 5. ì ìˆ˜ìˆœ ì •ë ¬\n",
        "        scored_mattresses.sort(key=lambda x: x[\"recommendation_score\"], reverse=True)\n",
        "\n",
        "        # âœ… ì˜ˆì‚° ì´ˆê³¼ ì œí’ˆ í•„í„°ë§ ì¶”ê°€\n",
        "        if user_prefs.get(\"budget\"):\n",
        "            scored_mattresses = [m for m in scored_mattresses if m.get(\"price\", 0) <= user_prefs[\"budget\"]]\n",
        "\n",
        "        # 6. Function Call: ìµœì¢… ì¶”ì²œ ìƒì„±\n",
        "        final_recommendations = self.function_caller.generate_recommendation(scored_mattresses)\n",
        "\n",
        "        return {\n",
        "            \"user_input\": user_input,\n",
        "            \"user_preferences\": user_prefs,\n",
        "            \"search_query\": search_query,\n",
        "            \"total_candidates\": len(mattresses),\n",
        "            \"recommendations\": final_recommendations[\"recommendations\"],\n",
        "            \"success\": True\n",
        "        }\n",
        "\n",
        "    def _create_search_query(self, preferences: Dict, original_input: str) -> str:\n",
        "        \"\"\"ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±\"\"\"\n",
        "        query_parts = []\n",
        "\n",
        "        # ê±´ê°• ë¬¸ì œ ìš°ì„ \n",
        "        if preferences[\"health_issues\"]:\n",
        "            query_parts.extend(preferences[\"health_issues\"])\n",
        "\n",
        "        # ì˜¨ë„ ì„ í˜¸ë„\n",
        "        if preferences[\"temperature_preference\"]:\n",
        "            query_parts.append(preferences[\"temperature_preference\"])\n",
        "\n",
        "        # ì˜ˆì‚°\n",
        "        if preferences[\"budget\"] > 0:\n",
        "            if preferences[\"budget\"] <= 200000:\n",
        "                query_parts.append(\"ì €ë ´í•œ ê°€ê²©\")\n",
        "            elif preferences[\"budget\"] <= 400000:\n",
        "                query_parts.append(\"ì¤‘ê°„ ê°€ê²©\")\n",
        "            else:\n",
        "                query_parts.append(\"ê³ ê¸‰ í”„ë¦¬ë¯¸ì—„\")\n",
        "\n",
        "        # ìˆ˜ë©´ìì„¸\n",
        "        if preferences[\"sleep_position\"]:\n",
        "            query_parts.append(f\"{preferences['sleep_position']} ìˆ˜ë©´\")\n",
        "\n",
        "        # ì»¤í”Œ\n",
        "        if preferences[\"partner\"]:\n",
        "            query_parts.append(\"ì»¤í”Œ ë§¤íŠ¸ë¦¬ìŠ¤\")\n",
        "\n",
        "        # ì¿¼ë¦¬ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ì…ë ¥ ì‚¬ìš©\n",
        "        if not query_parts:\n",
        "            return original_input\n",
        "\n",
        "        return \" \".join(query_parts)\n",
        "\n",
        "# AI Agent ì´ˆê¸°í™”\n",
        "if 'function_caller' in locals():\n",
        "    ai_agent = MattressRecommendationAgent(function_caller, prompt_engine, llm_generator)\n",
        "    print(\"âœ… AI Agent ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
        "else:\n",
        "    print(\"âŒ Function Calling ì‹œìŠ¤í…œì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"âœ… Phase 3 ì™„ë£Œ!\")\n",
        "print(\"ğŸ¯ êµ¬í˜„ëœ ê¸°ëŠ¥:\")\n",
        "print(\"- Function Calling ì‹œìŠ¤í…œ (5ê°œ í•¨ìˆ˜)\")\n",
        "print(\"- ê³ ê¸‰ Prompt Engineering (Role-based, CoT, Few-shot)\")\n",
        "print(\"- ì‚¬ìš©ì ì…ë ¥ ë¶„ì„ ë° ì„ í˜¸ë„ ì¶”ì¶œ\")\n",
        "print(\"- ì ìˆ˜ ê¸°ë°˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ ì‹œìŠ¤í…œ\")\n",
        "print(\"- AI Agent ë©”ì¸ í´ë˜ìŠ¤\")\n",
        "print(\"\\në‹¤ìŒ ë‹¨ê³„: Phase 4 - ì›¹ ì¸í„°í˜ì´ìŠ¤ ë° í†µí•© í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySQEi5unOkUY",
        "outputId": "33de0aa3-5473-4a06-ce49-48447e225ae1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… AI Agent ì´ˆê¸°í™” ì™„ë£Œ!\n",
            "\n",
            "==================================================\n",
            "âœ… Phase 3 ì™„ë£Œ!\n",
            "ğŸ¯ êµ¬í˜„ëœ ê¸°ëŠ¥:\n",
            "- Function Calling ì‹œìŠ¤í…œ (5ê°œ í•¨ìˆ˜)\n",
            "- ê³ ê¸‰ Prompt Engineering (Role-based, CoT, Few-shot)\n",
            "- ì‚¬ìš©ì ì…ë ¥ ë¶„ì„ ë° ì„ í˜¸ë„ ì¶”ì¶œ\n",
            "- ì ìˆ˜ ê¸°ë°˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ ì‹œìŠ¤í…œ\n",
            "- AI Agent ë©”ì¸ í´ë˜ìŠ¤\n",
            "\n",
            "ë‹¤ìŒ ë‹¨ê³„: Phase 4 - ì›¹ ì¸í„°í˜ì´ìŠ¤ ë° í†µí•© í…ŒìŠ¤íŠ¸\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. ì›¹ ì¸í„°í˜ì´ìŠ¤ ë° í†µí•© í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "FjbuBr09O81x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Streamlit ì„¤ì¹˜ ë° í„°ë„ë§ ë„êµ¬ ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "_cDfWKDgQQnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 4: ì›¹ ì¸í„°í˜ì´ìŠ¤ ë° í†µí•© í…ŒìŠ¤íŠ¸ - Streamlit\n",
        "# 1. Streamlit ì„¤ì¹˜ ë° í„°ë„ë§ ë„êµ¬ ì„¤ì¹˜\n",
        "!pip install streamlit pyngrok -q\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime\n",
        "import time"
      ],
      "metadata": {
        "id": "gAdKkP4FO_yL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Colabì—ì„œ Streamlit ì‹¤í–‰ì„ ìœ„í•œ ì„¤ì •"
      ],
      "metadata": {
        "id": "cpJhPRrHQJ5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Colabì—ì„œ Streamlit ì‹¤í–‰ì„ ìœ„í•œ ì„¤ì •\n",
        "# Streamlit ì•± ì½”ë“œë¥¼ íŒŒì¼ë¡œ ì €ì¥\n",
        "streamlit_app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# í˜ì´ì§€ ì„¤ì •\n",
        "st.set_page_config(\n",
        "    page_title=\"ë§¤íŠ¸ë¦¬ìŠ¤ êµ¬ë§¤ ê°€ì´ë“œ AI Agent\",\n",
        "    page_icon=\"ğŸ›ï¸\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# CSS ìŠ¤íƒ€ì¼ë§\n",
        "st.markdown('''\n",
        "<style>\n",
        "    .main-header {\n",
        "        font-size: 2.5rem;\n",
        "        color: #2E86AB;\n",
        "        text-align: center;\n",
        "        margin-bottom: 2rem;\n",
        "    }\n",
        "    .recommendation-card {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        color: white;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "    .score-badge {\n",
        "        background: #28a745;\n",
        "        color: white;\n",
        "        padding: 0.2rem 0.8rem;\n",
        "        border-radius: 20px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .chat-message {\n",
        "        padding: 1rem;\n",
        "        border-radius: 10px;\n",
        "        margin: 0.5rem 0;\n",
        "    }\n",
        "    .user-message {\n",
        "        background-color: #e3f2fd;\n",
        "        text-align: right;\n",
        "    }\n",
        "    .bot-message {\n",
        "        background-color: #f5f5f5;\n",
        "    }\n",
        "</style>\n",
        "''', unsafe_allow_html=True)\n",
        "\n",
        "# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”\n",
        "if 'messages' not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "if 'recommendations' not in st.session_state:\n",
        "    st.session_state.recommendations = []\n",
        "\n",
        "# ë©”ì¸ í—¤ë”\n",
        "st.markdown('<h1 class=\"main-header\">ğŸ›ï¸ ë§¤íŠ¸ë¦¬ìŠ¤ êµ¬ë§¤ ê°€ì´ë“œ AI Agent</h1>', unsafe_allow_html=True)\n",
        "\n",
        "# ì‚¬ì´ë“œë°” - ì‚¬ìš©ì ì •ë³´ ì…ë ¥\n",
        "st.sidebar.header(\"ğŸ’­ ìƒì„¸ ì •ë³´ ì…ë ¥ (ì„ íƒì‚¬í•­)\")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.markdown(\"### ê¸°ë³¸ ì •ë³´\")\n",
        "    sleep_position = st.selectbox(\n",
        "        \"ì£¼ìš” ìˆ˜ë©´ìì„¸\",\n",
        "        [\"ì„ íƒì•ˆí•¨\", \"ì˜†ìœ¼ë¡œ ëˆ„ì›Œì„œ\", \"ë“±ì„ ëŒ€ê³ \", \"ì—ë“œë ¤ì„œ\"],\n",
        "        key=\"sleep_pos\"\n",
        "    )\n",
        "\n",
        "    body_weight = st.selectbox(\n",
        "        \"ì²´ì¤‘ëŒ€\",\n",
        "        [\"ì„ íƒì•ˆí•¨\", \"ê°€ë²¼ìš´ í¸ (60kg ì´í•˜)\", \"ë³´í†µ (60-80kg)\", \"ë¬´ê±°ìš´ í¸ (80kg ì´ìƒ)\"],\n",
        "        key=\"weight\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### ì˜ˆì‚° ë° ì„ í˜¸ë„\")\n",
        "    budget = st.slider(\"ì˜ˆì‚° (ë§Œì›)\", 0, 100, 0, 5)\n",
        "\n",
        "    health_issues = st.multiselect(\n",
        "        \"ê±´ê°• ê´€ë ¨ ë¬¸ì œ\",\n",
        "        [\"í—ˆë¦¬í†µì¦\", \"ê´€ì ˆì—¼\", \"ëª©í†µì¦\", \"ìˆ˜ë©´ì¥ì• \", \"ì•Œë ˆë¥´ê¸°\"],\n",
        "        key=\"health\"\n",
        "    )\n",
        "\n",
        "    temperature_pref = st.radio(\n",
        "        \"ì˜¨ë„ ì„ í˜¸ë„\",\n",
        "        [\"ì„ íƒì•ˆí•¨\", \"ì‹œì›í•œ í™˜ê²½ ì„ í˜¸\", \"ë”°ëœ»í•œ í™˜ê²½ ì„ í˜¸\"],\n",
        "        key=\"temp\"\n",
        "    )\n",
        "\n",
        "    partner_use = st.checkbox(\"ì»¤í”Œ ì‚¬ìš©\", key=\"partner\")\n",
        "\n",
        "# ë©”ì¸ ì˜ì—­ì„ ë‘ ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„í• \n",
        "col1, col2 = st.columns([2, 1])\n",
        "\n",
        "with col1:\n",
        "    st.header(\"ğŸ’¬ AI ìƒë‹´ ì±„íŒ…\")\n",
        "\n",
        "    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ\n",
        "    for message in st.session_state.messages:\n",
        "        if message[\"role\"] == \"user\":\n",
        "            st.markdown(f'''\n",
        "            <div class=\"chat-message user-message\">\n",
        "                <strong>ğŸ‘¤ You:</strong> {message[\"content\"]}\n",
        "            </div>\n",
        "            ''', unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(f'''\n",
        "            <div class=\"chat-message bot-message\">\n",
        "                <strong>ğŸ¤– AI Agent:</strong> {message[\"content\"]}\n",
        "            </div>\n",
        "            ''', unsafe_allow_html=True)\n",
        "\n",
        "    # ì‚¬ìš©ì ì…ë ¥\n",
        "    user_input = st.text_input(\n",
        "        \"ğŸ’­ ë§¤íŠ¸ë¦¬ìŠ¤ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!\",\n",
        "        placeholder=\"ì˜ˆ: í—ˆë¦¬ê°€ ì•„í”ˆ í¸ì´ê³ , ì˜ˆì‚°ì€ 50ë§Œì› ì •ë„ì…ë‹ˆë‹¤.\",\n",
        "        key=\"user_input\"\n",
        "    )\n",
        "\n",
        "    if st.button(\"ğŸ’¬ AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°\", type=\"primary\"):\n",
        "        if user_input:\n",
        "            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "            # AI ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ai_agent.recommend_mattresses() í˜¸ì¶œ)\n",
        "            with st.spinner(\"ğŸ¤– AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\"):\n",
        "                time.sleep(2)  # ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜\n",
        "\n",
        "                # ë”ë¯¸ ì¶”ì²œ ê²°ê³¼ (ì‹¤ì œë¡œëŠ” AI Agent ê²°ê³¼ ì‚¬ìš©)\n",
        "                dummy_recommendations = [\n",
        "                    {\n",
        "                        \"name\": \"IKEA HÃ„FSLO ë§¤íŠ¸ë¦¬ìŠ¤\",\n",
        "                        \"brand\": \"IKEA\",\n",
        "                        \"type\": \"ìŠ¤í”„ë§\",\n",
        "                        \"price\": 179000,\n",
        "                        \"firmness\": \"ì¤‘ê°„\",\n",
        "                        \"recommendation_score\": 0.85,\n",
        "                        \"similarity_score\": 0.92\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"ì˜¤ëŠ˜ì˜ì§‘ í”„ë¦¬ë¯¸ì—„ ë©”ëª¨ë¦¬í¼\",\n",
        "                        \"brand\": \"ì˜¤ëŠ˜ì˜ì§‘\",\n",
        "                        \"type\": \"ë©”ëª¨ë¦¬í¼\",\n",
        "                        \"price\": 299000,\n",
        "                        \"firmness\": \"ì†Œí”„íŠ¸-ë¯¸ë””ì›€\",\n",
        "                        \"recommendation_score\": 0.78,\n",
        "                        \"similarity_score\": 0.88\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"í•œìƒ˜ ì²œì—°ë¼í…ìŠ¤ ë§¤íŠ¸ë¦¬ìŠ¤\",\n",
        "                        \"brand\": \"í•œìƒ˜\",\n",
        "                        \"type\": \"ë¼í…ìŠ¤\",\n",
        "                        \"price\": 450000,\n",
        "                        \"firmness\": \"ë¯¸ë””ì›€\",\n",
        "                        \"recommendation_score\": 0.72,\n",
        "                        \"similarity_score\": 0.85\n",
        "                    }\n",
        "                ]\n",
        "\n",
        "                st.session_state.recommendations = dummy_recommendations\n",
        "\n",
        "                # AI ì‘ë‹µ ìƒì„±\n",
        "                ai_response = f'''\n",
        "                ì•ˆë…•í•˜ì„¸ìš”! ê³ ê°ë‹˜ì˜ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "                ğŸ“Š **ë¶„ì„ ê²°ê³¼:**\n",
        "                - ì…ë ¥í•˜ì‹  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {len(dummy_recommendations)}ê°œì˜ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n",
        "                - ê°€ê²©, íƒ€ì…, ê±´ê°• ìƒíƒœ ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "                ğŸ† **1ìˆœìœ„ ì¶”ì²œ:** {dummy_recommendations[0]['name']}\n",
        "                - ì¶”ì²œ ì ìˆ˜: {dummy_recommendations[0]['recommendation_score']:.1%}\n",
        "                - ê°€ê²©: {dummy_recommendations[0]['price']:,}ì›\n",
        "                - ì¶”ì²œ ì´ìœ : ê³ ê°ë‹˜ì˜ ìš”êµ¬ì‚¬í•­ì— ê°€ì¥ ì í•©í•œ ìŠ¤í”„ë§ ë§¤íŠ¸ë¦¬ìŠ¤ì…ë‹ˆë‹¤.\n",
        "\n",
        "                ë” ìì„¸í•œ ì¶”ì²œ ê²°ê³¼ëŠ” ì˜¤ë¥¸ìª½ íŒ¨ë„ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ¯\n",
        "                '''\n",
        "\n",
        "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "\n",
        "            st.rerun()\n",
        "\n",
        "with col2:\n",
        "    st.header(\"ğŸ¯ ì¶”ì²œ ê²°ê³¼\")\n",
        "\n",
        "    if st.session_state.recommendations:\n",
        "        # ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤ ì¹´ë“œë“¤\n",
        "        for i, mattress in enumerate(st.session_state.recommendations):\n",
        "            with st.container():\n",
        "                st.markdown(f'''\n",
        "                <div class=\"recommendation-card\">\n",
        "                    <h3>#{i+1} {mattress['name']}</h3>\n",
        "                    <p><strong>ë¸Œëœë“œ:</strong> {mattress['brand']}</p>\n",
        "                    <p><strong>íƒ€ì…:</strong> {mattress['type']}</p>\n",
        "                    <p><strong>ê°€ê²©:</strong> {mattress['price']:,}ì›</p>\n",
        "                    <p><strong>ë‹¨ë‹¨í•¨:</strong> {mattress['firmness']}</p>\n",
        "                    <p><span class=\"score-badge\">ì¶”ì²œë„: {mattress['recommendation_score']:.1%}</span></p>\n",
        "                </div>\n",
        "                ''', unsafe_allow_html=True)\n",
        "\n",
        "        # ê°€ê²© ë¹„êµ ì°¨íŠ¸\n",
        "        st.subheader(\"ğŸ“Š ê°€ê²© ë¹„êµ\")\n",
        "        df = pd.DataFrame(st.session_state.recommendations)\n",
        "\n",
        "        fig = px.bar(\n",
        "            df,\n",
        "            x='name',\n",
        "            y='price',\n",
        "            color='recommendation_score',\n",
        "            title=\"ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤ ê°€ê²© ë¹„êµ\",\n",
        "            color_continuous_scale=\"viridis\"\n",
        "        )\n",
        "        fig.update_layout(height=400)\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        # ì ìˆ˜ ë¹„êµ ì°¨íŠ¸\n",
        "        st.subheader(\"ğŸ¯ ì¶”ì²œ ì ìˆ˜ ë¹„êµ\")\n",
        "        fig2 = go.Figure(data=[\n",
        "            go.Bar(\n",
        "                x=df['name'],\n",
        "                y=df['recommendation_score'],\n",
        "                text=[f\"{score:.1%}\" for score in df['recommendation_score']],\n",
        "                textposition='auto',\n",
        "                marker_color='lightblue'\n",
        "            )\n",
        "        ])\n",
        "        fig2.update_layout(\n",
        "            title=\"ë§¤íŠ¸ë¦¬ìŠ¤ë³„ ì¶”ì²œ ì ìˆ˜\",\n",
        "            yaxis_title=\"ì¶”ì²œ ì ìˆ˜\",\n",
        "            height=400\n",
        "        )\n",
        "        st.plotly_chart(fig2, use_container_width=True)\n",
        "\n",
        "    else:\n",
        "        st.info(\"ğŸ’¡ ì™¼ìª½ ì±„íŒ…ì°½ì—ì„œ ë§¤íŠ¸ë¦¬ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”!\")\n",
        "\n",
        "        # ìƒ˜í”Œ ì§ˆë¬¸ ì œê³µ\n",
        "        st.markdown(\"### ğŸ’­ ìƒ˜í”Œ ì§ˆë¬¸ë“¤\")\n",
        "        sample_questions = [\n",
        "            \"í—ˆë¦¬ê°€ ì•„í”ˆ í¸ì´ê³ , ì˜ˆì‚°ì€ 50ë§Œì› ì •ë„ì…ë‹ˆë‹¤.\",\n",
        "            \"ë”ìœ„ë¥¼ ë§ì´ íƒ€ì„œ ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”.\",\n",
        "            \"ì»¤í”Œì´ ì‚¬ìš©í•  ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.\",\n",
        "            \"ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤. ì¶”ì²œí•´ì£¼ì„¸ìš”.\"\n",
        "        ]\n",
        "\n",
        "        for question in sample_questions:\n",
        "            if st.button(f\"ğŸ’¬ {question}\", key=f\"sample_{question[:10]}\"):\n",
        "                st.session_state.messages.append({\"role\": \"user\", \"content\": question})\n",
        "                st.rerun()\n",
        "\n",
        "# í•˜ë‹¨ ì •ë³´\n",
        "st.markdown(\"---\")\n",
        "col_info1, col_info2, col_info3 = st.columns(3)\n",
        "\n",
        "with col_info1:\n",
        "    st.metric(\"ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤\", \"10ê°œ ë§¤íŠ¸ë¦¬ìŠ¤\", \"RAG ì‹œìŠ¤í…œ\")\n",
        "\n",
        "with col_info2:\n",
        "    st.metric(\"ğŸ¤– AI ëª¨ë¸\", \"Sentence Transformer\", \"ChromaDB\")\n",
        "\n",
        "with col_info3:\n",
        "    st.metric(\"ğŸ’¬ ìƒë‹´ íšŸìˆ˜\", len(st.session_state.messages)//2, \"ì‹¤ì‹œê°„ ë¶„ì„\")\n",
        "\n",
        "# í‘¸í„°\n",
        "st.markdown('''\n",
        "---\n",
        "<div style=\"text-align: center; color: #666;\">\n",
        "    ğŸ›ï¸ <strong>ë§¤íŠ¸ë¦¬ìŠ¤ êµ¬ë§¤ ê°€ì´ë“œ AI Agent</strong> |\n",
        "    Powered by RAG + Function Calling + ChromaDB\n",
        "</div>\n",
        "''', unsafe_allow_html=True)\n",
        "\"\"\"\n",
        "\n",
        "# Streamlit ì•± íŒŒì¼ ì €ì¥\n",
        "with open('/content/mattress_ai_app.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(streamlit_app_code)"
      ],
      "metadata": {
        "id": "sYzTtvO_QJpm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) ì‹¤ì œ AI Agent í†µí•© ë²„ì „ ìƒì„±"
      ],
      "metadata": {
        "id": "cdyh-IfzP-TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. ì‹¤ì œ AI Agent í†µí•© ë²„ì „ ìƒì„±\n",
        "integrated_app_code = '''\n",
        "import streamlit as st\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Colab í™˜ê²½ì—ì„œ í•„ìš”í•œ ëª¨ë“ˆë“¤ ì„í¬íŠ¸ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ìˆ˜ì • í•„ìš”)\n",
        "try:\n",
        "    # ì‹¤ì œ AI Agent í´ë˜ìŠ¤ë“¤ì„ ì„í¬íŠ¸ (Phase 1-3ì—ì„œ êµ¬í˜„í•œ ê²ƒë“¤)\n",
        "    # from your_ai_agent_module import MattressRecommendationAgent, MattressFunctionCalling\n",
        "\n",
        "    # ì„ì‹œë¡œ ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©\n",
        "    class DummyAIAgent:\n",
        "        def recommend_mattresses(self, user_input):\n",
        "            # ì‹¤ì œë¡œëŠ” ai_agent.recommend_mattresses(user_input) í˜¸ì¶œ\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"user_input\": user_input,\n",
        "                \"recommendations\": [\n",
        "                    {\n",
        "                        \"name\": \"IKEA HÃ„FSLO ë§¤íŠ¸ë¦¬ìŠ¤\",\n",
        "                        \"brand\": \"IKEA\",\n",
        "                        \"type\": \"ìŠ¤í”„ë§\",\n",
        "                        \"price\": 179000,\n",
        "                        \"firmness\": \"ì¤‘ê°„\",\n",
        "                        \"recommendation_score\": 0.85\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "\n",
        "    # AI Agent ì´ˆê¸°í™”\n",
        "    ai_agent = DummyAIAgent()\n",
        "\n",
        "except Exception as e:\n",
        "    st.error(f\"AI Agent ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "    ai_agent = None\n",
        "\n",
        "# í˜ì´ì§€ ì„¤ì •\n",
        "st.set_page_config(\n",
        "    page_title=\"ë§¤íŠ¸ë¦¬ìŠ¤ AI Agent - í†µí•© ë²„ì „\",\n",
        "    page_icon=\"ğŸ›ï¸\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.title(\"ğŸ›ï¸ ë§¤íŠ¸ë¦¬ìŠ¤ êµ¬ë§¤ ê°€ì´ë“œ AI Agent (í†µí•© ë²„ì „)\")\n",
        "\n",
        "# ì‹¤ì œ AI Agent ì‚¬ìš©\n",
        "if ai_agent:\n",
        "    user_input = st.text_input(\"ë§¤íŠ¸ë¦¬ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”:\")\n",
        "\n",
        "    if st.button(\"AI ì¶”ì²œ ë°›ê¸°\"):\n",
        "        if user_input:\n",
        "            with st.spinner(\"AIê°€ ë¶„ì„ ì¤‘...\"):\n",
        "                result = ai_agent.recommend_mattresses(user_input)\n",
        "\n",
        "                if result.get(\"success\"):\n",
        "                    st.success(\"âœ… ì¶”ì²œ ì™„ë£Œ!\")\n",
        "\n",
        "                    for i, rec in enumerate(result[\"recommendations\"]):\n",
        "                        st.markdown(f\"\"\"\n",
        "                        ### {i+1}. {rec['name']}\n",
        "                        - **ë¸Œëœë“œ**: {rec['brand']}\n",
        "                        - **íƒ€ì…**: {rec['type']}\n",
        "                        - **ê°€ê²©**: {rec['price']:,}ì›\n",
        "                        - **ì¶”ì²œ ì ìˆ˜**: {rec['recommendation_score']:.1%}\n",
        "                        \"\"\")\n",
        "                else:\n",
        "                    st.error(\"ì¶”ì²œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    st.error(\"AI Agentë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Phase 1-3ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "'''\n",
        "\n",
        "with open('/content/integrated_app.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(integrated_app_code)"
      ],
      "metadata": {
        "id": "-2-WmF3vP-F5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Colabì—ì„œ Streamlit ì‹¤í–‰ ë°©ë²• ì•ˆë‚´"
      ],
      "metadata": {
        "id": "H-GXXO8uP34D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Colabì—ì„œ Streamlit ì‹¤í–‰ ë°©ë²• ì•ˆë‚´\n",
        "execution_guide = \"\"\"\n",
        "ğŸŒ Colabì—ì„œ Streamlit ì•± ì‹¤í–‰í•˜ê¸°:\n",
        "\n",
        "ë°©ë²• 1: ë¡œì»¬ í„°ë„ë§ (ngrok ì‚¬ìš©)\n",
        "================================\n",
        "1. ì•„ë˜ ì½”ë“œë¥¼ ìƒˆ ì…€ì—ì„œ ì‹¤í–‰:\n",
        "\n",
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# ngrok í† í° ì„¤ì • (ngrok.comì—ì„œ ë¬´ë£Œ ê³„ì • ìƒì„± í›„)\n",
        "# ngrok.set_auth_token(\"YOUR_NGROK_TOKEN\")\n",
        "\n",
        "# Streamlit ì•± ì‹¤í–‰ í•¨ìˆ˜\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"/content/mattress_ai_app.py\", \"--server.port=8501\"])\n",
        "\n",
        "# ë°±ê·¸ë¼ìš´ë“œì—ì„œ Streamlit ì‹¤í–‰\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "# ì ì‹œ ëŒ€ê¸° í›„ ngrok í„°ë„ ìƒì„±\n",
        "time.sleep(10)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"ğŸŒ Streamlit ì•± URL: {public_url}\")\n",
        "\n",
        "ë°©ë²• 2: ë¡œì»¬ í¬íŠ¸ ì‚¬ìš©\n",
        "=====================\n",
        "!streamlit run /content/mattress_ai_app.py --server.port=8501 &\n",
        "\n",
        "ê·¸ í›„ Colab ìƒë‹¨ì˜ \"í¬íŠ¸\" ë²„íŠ¼ í´ë¦­í•˜ì—¬ 8501 í¬íŠ¸ í™•ì¸\n",
        "\n",
        "ë°©ë²• 3: ì½”ë“œ ë‹¤ìš´ë¡œë“œ í›„ ë¡œì»¬ ì‹¤í–‰\n",
        "================================\n",
        "1. ì•„ë˜ ì½”ë“œë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ:\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/mattress_ai_app.py')\n",
        "\n",
        "2. ë¡œì»¬ì—ì„œ ì‹¤í–‰:\n",
        "\n",
        "streamlit run mattress_ai_app.py\n",
        "\"\"\"\n",
        "\n",
        "print(execution_guide)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP-v2fcwP3mV",
        "outputId": "bb117a7d-0534-4286-9d99-8bb24c63639f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸŒ Colabì—ì„œ Streamlit ì•± ì‹¤í–‰í•˜ê¸°:\n",
            "\n",
            "ë°©ë²• 1: ë¡œì»¬ í„°ë„ë§ (ngrok ì‚¬ìš©)\n",
            "================================\n",
            "1. ì•„ë˜ ì½”ë“œë¥¼ ìƒˆ ì…€ì—ì„œ ì‹¤í–‰:\n",
            "\n",
            "!pip install pyngrok\n",
            "from pyngrok import ngrok\n",
            "import threading\n",
            "import subprocess\n",
            "import time\n",
            "\n",
            "# ngrok í† í° ì„¤ì • (ngrok.comì—ì„œ ë¬´ë£Œ ê³„ì • ìƒì„± í›„)\n",
            "# ngrok.set_auth_token(\"YOUR_NGROK_TOKEN\")\n",
            "\n",
            "# Streamlit ì•± ì‹¤í–‰ í•¨ìˆ˜\n",
            "def run_streamlit():\n",
            "    subprocess.run([\"streamlit\", \"run\", \"/content/mattress_ai_app.py\", \"--server.port=8501\"])\n",
            "\n",
            "# ë°±ê·¸ë¼ìš´ë“œì—ì„œ Streamlit ì‹¤í–‰\n",
            "thread = threading.Thread(target=run_streamlit)\n",
            "thread.daemon = True\n",
            "thread.start()\n",
            "\n",
            "# ì ì‹œ ëŒ€ê¸° í›„ ngrok í„°ë„ ìƒì„±\n",
            "time.sleep(10)\n",
            "public_url = ngrok.connect(8501)\n",
            "print(f\"ğŸŒ Streamlit ì•± URL: {public_url}\")\n",
            "\n",
            "ë°©ë²• 2: ë¡œì»¬ í¬íŠ¸ ì‚¬ìš©\n",
            "=====================\n",
            "!streamlit run /content/mattress_ai_app.py --server.port=8501 &\n",
            "\n",
            "ê·¸ í›„ Colab ìƒë‹¨ì˜ \"í¬íŠ¸\" ë²„íŠ¼ í´ë¦­í•˜ì—¬ 8501 í¬íŠ¸ í™•ì¸\n",
            "\n",
            "ë°©ë²• 3: ì½”ë“œ ë‹¤ìš´ë¡œë“œ í›„ ë¡œì»¬ ì‹¤í–‰\n",
            "================================\n",
            "1. ì•„ë˜ ì½”ë“œë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ:\n",
            "\n",
            "from google.colab import files\n",
            "files.download('/content/mattress_ai_app.py')\n",
            "\n",
            "2. ë¡œì»¬ì—ì„œ ì‹¤í–‰:\n",
            "\n",
            "streamlit run mattress_ai_app.py\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) í†µí•© í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "nPGC57wlPujL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. í†µí•© í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
        "def run_integration_test():\n",
        "    \"\"\"ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸\"\"\"\n",
        "    print(\"\\nğŸ§ª ë§¤íŠ¸ë¦¬ìŠ¤ AI Agent í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\": \"í—ˆë¦¬ í†µì¦ ì‚¬ìš©ì\",\n",
        "            \"input\": \"í—ˆë¦¬ê°€ ì•„í”ˆ í¸ì´ê³ , ì˜ˆì‚°ì€ 50ë§Œì› ì •ë„ì…ë‹ˆë‹¤.\",\n",
        "            \"expected\": [\"í—ˆë¦¬í†µì¦\", \"ì˜ˆì‚°\", \"ë©”ëª¨ë¦¬í¼\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"ë”ìœ„ ë§ì´ íƒ€ëŠ” ì‚¬ìš©ì\",\n",
        "            \"input\": \"ë”ìœ„ë¥¼ ë§ì´ íƒ€ì„œ ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”.\",\n",
        "            \"expected\": [\"ì‹œì›í•¨\", \"ì ¤\", \"í•˜ì´ë¸Œë¦¬ë“œ\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"ì»¤í”Œ ì‚¬ìš©ì\",\n",
        "            \"input\": \"ì»¤í”Œì´ ì‚¬ìš©í•  ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”. ì›€ì§ì„ ì°¨ë‹¨ì´ ì¤‘ìš”í•´ìš”.\",\n",
        "            \"expected\": [\"ì»¤í”Œ\", \"ì›€ì§ì„\", \"ë©”ëª¨ë¦¬í¼\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for i, test_case in enumerate(test_cases, 1):\n",
        "        print(f\"\\nğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}: {test_case['name']}\")\n",
        "        print(f\"ì…ë ¥: {test_case['input']}\")\n",
        "\n",
        "        try:\n",
        "            # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ai_agent.recommend_mattresses() í˜¸ì¶œ\n",
        "            # result = ai_agent.recommend_mattresses(test_case['input'])\n",
        "\n",
        "            # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼\n",
        "            result = {\n",
        "                \"success\": True,\n",
        "                \"user_preferences\": {\"budget\": 500000, \"health_issues\": [\"í—ˆë¦¬í†µì¦\"]},\n",
        "                \"recommendations\": [\n",
        "                    {\"name\": \"í…ŒìŠ¤íŠ¸ ë§¤íŠ¸ë¦¬ìŠ¤\", \"score\": 0.85}\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            if result.get(\"success\"):\n",
        "                print(\"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
        "                print(f\"   ì¶”ì²œ ê²°ê³¼: {len(result.get('recommendations', []))}ê°œ\")\n",
        "            else:\n",
        "                print(\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}\")"
      ],
      "metadata": {
        "id": "01rG2AtTPrVo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥"
      ],
      "metadata": {
        "id": "S1vpki1qPnYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥\n",
        "def download_project_files():\n",
        "    \"\"\"í”„ë¡œì íŠ¸ íŒŒì¼ë“¤ì„ ë‹¤ìš´ë¡œë“œ\"\"\"\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"ğŸ“¥ í”„ë¡œì íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "    try:\n",
        "        # Streamlit ì•± ë‹¤ìš´ë¡œë“œ\n",
        "        files.download('/content/mattress_ai_app.py')\n",
        "        print(\"âœ… mattress_ai_app.py ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")\n",
        "\n",
        "        # í†µí•© ì•± ë‹¤ìš´ë¡œë“œ\n",
        "        files.download('/content/integrated_app.py')\n",
        "        print(\"âœ… integrated_app.py ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")\n",
        "\n",
        "        print(\"\\nğŸ¯ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë“¤:\")\n",
        "        print(\"- mattress_ai_app.py: ì™„ì „í•œ Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤\")\n",
        "        print(\"- integrated_app.py: AI Agent í†µí•© ë²„ì „\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}\")"
      ],
      "metadata": {
        "id": "UghSf6DaO_tw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_integration_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsXRsTySO_pF",
        "outputId": "5d8e4f8f-2519-47e8-fc06-15d8f114de43"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§ª ë§¤íŠ¸ë¦¬ìŠ¤ AI Agent í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
            "==================================================\n",
            "\n",
            "ğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: í—ˆë¦¬ í†µì¦ ì‚¬ìš©ì\n",
            "ì…ë ¥: í—ˆë¦¬ê°€ ì•„í”ˆ í¸ì´ê³ , ì˜ˆì‚°ì€ 50ë§Œì› ì •ë„ì…ë‹ˆë‹¤.\n",
            "âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
            "   ì¶”ì²œ ê²°ê³¼: 1ê°œ\n",
            "\n",
            "ğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ë”ìœ„ ë§ì´ íƒ€ëŠ” ì‚¬ìš©ì\n",
            "ì…ë ¥: ë”ìœ„ë¥¼ ë§ì´ íƒ€ì„œ ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”.\n",
            "âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
            "   ì¶”ì²œ ê²°ê³¼: 1ê°œ\n",
            "\n",
            "ğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ì»¤í”Œ ì‚¬ìš©ì\n",
            "ì…ë ¥: ì»¤í”Œì´ ì‚¬ìš©í•  ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”. ì›€ì§ì„ ì°¨ë‹¨ì´ ì¤‘ìš”í•´ìš”.\n",
            "âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
            "   ì¶”ì²œ ê²°ê³¼: 1ê°œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. ì‚¬ìš©ì ì§ˆë¬¸-ë‹µë³€ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "JEBPe_YISPw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹¤ì œ AI Agentê°€ ì‚¬ìš©ì ì§ˆë¬¸ì— ì–¼ë§ˆë‚˜ ì˜ ë‹µë³€í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸\n",
        "import json\n",
        "from typing import Dict, List, Tuple\n",
        "import re\n",
        "\n",
        "# 1. ë‹µë³€ í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜\n",
        "def evaluate_answer_quality(user_question: str, ai_response: Dict, expected_criteria: List[str]) -> Dict:\n",
        "    \"\"\"\n",
        "    AI Agent ë‹µë³€ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Args:\n",
        "        user_question: ì‚¬ìš©ì ì§ˆë¬¸\n",
        "        ai_response: AI Agentì˜ ì‘ë‹µ ê²°ê³¼\n",
        "        expected_criteria: ê¸°ëŒ€ë˜ëŠ” ë‹µë³€ ê¸°ì¤€ë“¤\n",
        "\n",
        "    Returns:\n",
        "        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬\n",
        "    \"\"\"\n",
        "\n",
        "    score = 0\n",
        "    max_score = 100\n",
        "    evaluation_details = {}\n",
        "\n",
        "    # 1. ì¶”ì²œ ê²°ê³¼ ì¡´ì¬ ì—¬ë¶€ (30ì )\n",
        "    if ai_response.get('success') and ai_response.get('recommendations'):\n",
        "        recommendations = ai_response['recommendations']\n",
        "        if len(recommendations) >= 1:\n",
        "            score += 30\n",
        "            evaluation_details['has_recommendations'] = f\"âœ… {len(recommendations)}ê°œ ì¶”ì²œ ì œê³µ\"\n",
        "        else:\n",
        "            evaluation_details['has_recommendations'] = \"âŒ ì¶”ì²œ ê²°ê³¼ ì—†ìŒ\"\n",
        "    else:\n",
        "        evaluation_details['has_recommendations'] = \"âŒ ì¶”ì²œ ì‹¤íŒ¨\"\n",
        "\n",
        "    # 2. ì‚¬ìš©ì ì„ í˜¸ë„ ë¶„ì„ ì •í™•ì„± (25ì )\n",
        "    user_prefs = ai_response.get('user_preferences', {})\n",
        "    analyzed_correctly = 0\n",
        "    total_prefs = len(expected_criteria)\n",
        "\n",
        "    for criteria in expected_criteria:\n",
        "        if criteria.lower() in str(user_prefs).lower() or criteria.lower() in user_question.lower():\n",
        "            analyzed_correctly += 1\n",
        "\n",
        "    if total_prefs > 0:\n",
        "        pref_score = (analyzed_correctly / total_prefs) * 25\n",
        "        score += pref_score\n",
        "        evaluation_details['preference_analysis'] = f\"âœ… {analyzed_correctly}/{total_prefs} ì„ í˜¸ë„ ì¸ì‹\"\n",
        "    else:\n",
        "        evaluation_details['preference_analysis'] = \"â„¹ï¸ í‰ê°€ ê¸°ì¤€ ì—†ìŒ\"\n",
        "\n",
        "    # 3. ì¶”ì²œ ë‹¤ì–‘ì„± (20ì )\n",
        "    if ai_response.get('recommendations'):\n",
        "        recommendations = ai_response['recommendations']\n",
        "\n",
        "        # ê°€ê²©ëŒ€ ë‹¤ì–‘ì„±\n",
        "        prices = [r.get('price', 0) for r in recommendations]\n",
        "        price_ranges = set()\n",
        "        for price in prices:\n",
        "            if price < 200000:\n",
        "                price_ranges.add('ì €ê°€')\n",
        "            elif price < 400000:\n",
        "                price_ranges.add('ì¤‘ê°€')\n",
        "            else:\n",
        "                price_ranges.add('ê³ ê°€')\n",
        "\n",
        "        # íƒ€ì… ë‹¤ì–‘ì„±\n",
        "        types = set([r.get('type', '') for r in recommendations])\n",
        "\n",
        "        diversity_score = min(20, len(price_ranges) * 7 + len(types) * 3)\n",
        "        score += diversity_score\n",
        "        evaluation_details['diversity'] = f\"âœ… ê°€ê²©ëŒ€ {len(price_ranges)}ì¢…ë¥˜, íƒ€ì… {len(types)}ì¢…ë¥˜\"\n",
        "    else:\n",
        "        evaluation_details['diversity'] = \"âŒ ë‹¤ì–‘ì„± í‰ê°€ ë¶ˆê°€\"\n",
        "\n",
        "    # 4. ê°€ê²© ì í•©ì„± (15ì )\n",
        "    budget = user_prefs.get('budget', 0)\n",
        "    if budget > 0 and ai_response.get('recommendations'):\n",
        "        affordable_count = sum(1 for r in ai_response['recommendations'] if r.get('price', 0) <= budget)\n",
        "        total_recs = len(ai_response['recommendations'])\n",
        "\n",
        "        if affordable_count > 0:\n",
        "            affordability_score = (affordable_count / total_recs) * 15\n",
        "            score += affordability_score\n",
        "            evaluation_details['price_fit'] = f\"âœ… {affordable_count}/{total_recs}ê°œê°€ ì˜ˆì‚° ë‚´\"\n",
        "        else:\n",
        "            evaluation_details['price_fit'] = \"âš ï¸ ì˜ˆì‚° ì´ˆê³¼ ì¶”ì²œ\"\n",
        "    else:\n",
        "        evaluation_details['price_fit'] = \"â„¹ï¸ ì˜ˆì‚° ì •ë³´ ì—†ìŒ\"\n",
        "\n",
        "    # 5. ì¶”ì²œ ìˆœì„œì˜ í•©ë¦¬ì„± (10ì )\n",
        "    if ai_response.get('recommendations') and len(ai_response['recommendations']) >= 2:\n",
        "        recs = ai_response['recommendations']\n",
        "\n",
        "        # ì¶”ì²œ ì ìˆ˜ ìˆœì„œ í™•ì¸\n",
        "        scores = [r.get('recommendation_score', 0) for r in recs]\n",
        "        is_sorted = all(scores[i] >= scores[i+1] for i in range(len(scores)-1))\n",
        "\n",
        "        if is_sorted:\n",
        "            score += 10\n",
        "            evaluation_details['ranking'] = \"âœ… ì¶”ì²œ ì ìˆ˜ ìˆœì„œ ì •í™•\"\n",
        "        else:\n",
        "            evaluation_details['ranking'] = \"âš ï¸ ì¶”ì²œ ìˆœì„œ ë¬¸ì œ\"\n",
        "    else:\n",
        "        evaluation_details['ranking'] = \"â„¹ï¸ ìˆœì„œ í‰ê°€ ë¶ˆê°€\"\n",
        "\n",
        "    return {\n",
        "        'score': min(score, max_score),\n",
        "        'max_score': max_score,\n",
        "        'percentage': min(score / max_score * 100, 100),\n",
        "        'grade': get_grade(score / max_score * 100),\n",
        "        'details': evaluation_details,\n",
        "        'user_question': user_question,\n",
        "        'recommendation_count': len(ai_response.get('recommendations', []))\n",
        "    }\n",
        "\n",
        "def get_grade(percentage: float) -> str:\n",
        "    \"\"\"ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
        "    if percentage >= 90:\n",
        "        return \"A+ (ìš°ìˆ˜)\"\n",
        "    elif percentage >= 80:\n",
        "        return \"A (ì–‘í˜¸)\"\n",
        "    elif percentage >= 70:\n",
        "        return \"B (ë³´í†µ)\"\n",
        "    elif percentage >= 60:\n",
        "        return \"C (ë¯¸í¡)\"\n",
        "    else:\n",
        "        return \"F (ë¶ˆëŸ‰)\""
      ],
      "metadata": {
        "id": "16mLYEIEOkR4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) ì‹¤ì œ ì‚¬ìš©ì ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤"
      ],
      "metadata": {
        "id": "3U4lh5Y-SjT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ì‹¤ì œ ì‚¬ìš©ì ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤\n",
        "def test_user_interactions():\n",
        "    \"\"\"ì‹¤ì œ ì‚¬ìš©ì ì§ˆë¬¸ë“¤ë¡œ AI Agent í…ŒìŠ¤íŠ¸\"\"\"\n",
        "\n",
        "    print(\"\\nğŸ—£ï¸ ì‹¤ì œ ì‚¬ìš©ì ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # ë‹¤ì–‘í•œ ì‚¬ìš©ì ì§ˆë¬¸ ì‹œë‚˜ë¦¬ì˜¤\n",
        "    test_scenarios = [\n",
        "        {\n",
        "            \"category\": \"í—ˆë¦¬ í†µì¦ ê³ ê°\",\n",
        "            \"question\": \"í—ˆë¦¬ê°€ ìì£¼ ì•„í”„ê³  ì¸¡ë©´ìœ¼ë¡œ ëˆ„ì›Œì„œ ìëŠ” í¸ì´ì—ìš”. ì˜ˆì‚°ì€ 50ë§Œì› ì •ë„ì¸ë° ì–´ë–¤ ë§¤íŠ¸ë¦¬ìŠ¤ê°€ ì¢‹ì„ê¹Œìš”?\",\n",
        "            \"expected_criteria\": [\"í—ˆë¦¬í†µì¦\", \"ì¸¡ë©´ìˆ˜ë©´\", \"ì˜ˆì‚° 50ë§Œì›\", \"ë©”ëª¨ë¦¬í¼\"],\n",
        "            \"expected_price_max\": 500000\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"ë”ìœ„ íƒ€ëŠ” ê³ ê°\",\n",
        "            \"question\": \"ë”ìœ„ë¥¼ ë§ì´ íƒ€ì„œ ë°¤ì— ìì£¼ ê¹¨ìš”. ì‹œì›í•˜ê²Œ ì˜ ìˆ˜ ìˆëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”. ê°€ê²©ì€ ìƒê´€ì—†ì–´ìš”.\",\n",
        "            \"expected_criteria\": [\"ë”ìœ„\", \"ì‹œì›í•¨\", \"í†µê¸°ì„±\", \"ì ¤\", \"í•˜ì´ë¸Œë¦¬ë“œ\"],\n",
        "            \"expected_price_max\": 1000000\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"ì»¤í”Œ ì‚¬ìš©ì\",\n",
        "            \"question\": \"ì‹ í˜¼ë¶€ë¶€ì¸ë° ì„œë¡œ ë’¤ì²™ì„ ë•Œë¬¸ì— ì ì„ ëª» ìê² ì–´ìš”. ì›€ì§ì„ì´ ì „ë‹¬ë˜ì§€ ì•ŠëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ ìˆë‚˜ìš”?\",\n",
        "            \"expected_criteria\": [\"ì»¤í”Œ\", \"ì›€ì§ì„ ì°¨ë‹¨\", \"motion isolation\", \"ë©”ëª¨ë¦¬í¼\"],\n",
        "            \"expected_price_max\": 800000\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"ì˜ˆì‚° ì œí•œ ê³ ê°\",\n",
        "            \"question\": \"ëŒ€í•™ìƒì´ë¼ ì˜ˆì‚°ì´ ë„‰ë„‰í•˜ì§€ ì•Šì•„ìš”. 20ë§Œì› ì´í•˜ë¡œ ê´œì°®ì€ ë§¤íŠ¸ë¦¬ìŠ¤ ìˆì„ê¹Œìš”?\",\n",
        "            \"expected_criteria\": [\"ì˜ˆì‚° ì œí•œ\", \"ì €ë ´í•œ\", \"í•™ìƒ\", \"ê¸°ë³¸í˜•\"],\n",
        "            \"expected_price_max\": 200000\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"ê³ ê¸‰ ì„ í˜¸ ê³ ê°\",\n",
        "            \"question\": \"í”„ë¦¬ë¯¸ì—„ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”. ìµœê³  í’ˆì§ˆì˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”. ê°€ê²©ì€ 100ë§Œì›ê¹Œì§€ ê°€ëŠ¥í•´ìš”.\",\n",
        "            \"expected_criteria\": [\"í”„ë¦¬ë¯¸ì—„\", \"ê³ í’ˆì§ˆ\", \"ìµœê³ ê¸‰\", \"í…œí¼\"],\n",
        "            \"expected_price_max\": 1000000\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"ê±´ê°• ë¬¸ì œ ê³ ê°\",\n",
        "            \"question\": \"ê´€ì ˆì—¼ì´ ìˆì–´ì„œ ì•„ì¹¨ì— ì¼ì–´ë‚˜ë©´ ëª¸ì´ ë»£ë»£í•´ìš”. ê´€ì ˆì— ì¢‹ì€ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.\",\n",
        "            \"expected_criteria\": [\"ê´€ì ˆì—¼\", \"ì²´ì••ë¶„ì‚°\", \"ë¼í…ìŠ¤\", \"ë©”ëª¨ë¦¬í¼\"],\n",
        "            \"expected_price_max\": 600000\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"ë‹¨ë‹¨í•¨ ì„ í˜¸ ê³ ê°\",\n",
        "            \"question\": \"ë¶€ë“œëŸ¬ìš´ ë§¤íŠ¸ë¦¬ìŠ¤ëŠ” í—ˆë¦¬ê°€ ì•„íŒŒìš”. ë”±ë”±í•˜ê³  ë‹¨ë‹¨í•œ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.\",\n",
        "            \"expected_criteria\": [\"ë”±ë”±í•œ\", \"ë‹¨ë‹¨í•œ\", \"íŒ\", \"ìŠ¤í”„ë§\"],\n",
        "            \"expected_price_max\": 500000\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"ì•Œë ˆë¥´ê¸° ê³ ê°\",\n",
        "            \"question\": \"ì•Œë ˆë¥´ê¸°ê°€ ì‹¬í•´ì„œ ì²œì—° ì†Œì¬ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”. í•­ê·  íš¨ê³¼ë„ ìˆìœ¼ë©´ ì¢‹ê² ì–´ìš”.\",\n",
        "            \"expected_criteria\": [\"ì•Œë ˆë¥´ê¸°\", \"ì²œì—°ì†Œì¬\", \"í•­ê· \", \"ë¼í…ìŠ¤\"],\n",
        "            \"expected_price_max\": 600000\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if 'ai_agent' not in globals():\n",
        "        print(\"âŒ AI Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        print(\"ğŸ’¡ Phase 3 ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "        return\n",
        "\n",
        "    total_score = 0\n",
        "    results = []\n",
        "\n",
        "    for i, scenario in enumerate(test_scenarios, 1):\n",
        "        print(f\"\\nğŸ¯ í…ŒìŠ¤íŠ¸ {i}: {scenario['category']}\")\n",
        "        print(f\"ì§ˆë¬¸: {scenario['question']}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        try:\n",
        "            # AI Agentì—ê²Œ ì§ˆë¬¸\n",
        "            ai_response = ai_agent.recommend_mattresses(scenario['question'])\n",
        "\n",
        "            # ë‹µë³€ í’ˆì§ˆ í‰ê°€\n",
        "            evaluation = evaluate_answer_quality(\n",
        "                scenario['question'],\n",
        "                ai_response,\n",
        "                scenario['expected_criteria']\n",
        "            )\n",
        "\n",
        "            results.append({\n",
        "                'scenario': scenario['category'],\n",
        "                'evaluation': evaluation\n",
        "            })\n",
        "\n",
        "            # ê²°ê³¼ ì¶œë ¥\n",
        "            print(f\"ğŸ“Š í‰ê°€ ì ìˆ˜: {evaluation['score']:.1f}/{evaluation['max_score']} ({evaluation['percentage']:.1f}%)\")\n",
        "            print(f\"ğŸ† ë“±ê¸‰: {evaluation['grade']}\")\n",
        "            print(f\"ğŸ“ ì¶”ì²œ ê°œìˆ˜: {evaluation['recommendation_count']}ê°œ\")\n",
        "\n",
        "            print(\"\\nğŸ“‹ ì„¸ë¶€ í‰ê°€:\")\n",
        "            for key, detail in evaluation['details'].items():\n",
        "                print(f\"   â€¢ {detail}\")\n",
        "\n",
        "            if ai_response.get('recommendations'):\n",
        "                print(f\"\\nğŸ† 1ìˆœìœ„ ì¶”ì²œ:\")\n",
        "                top_rec = ai_response['recommendations'][0]\n",
        "                print(f\"   {top_rec.get('name', 'Unknown')} ({top_rec.get('brand', 'Unknown')})\")\n",
        "                print(f\"   ê°€ê²©: {top_rec.get('price', 0):,}ì›\")\n",
        "                print(f\"   íƒ€ì…: {top_rec.get('type', 'Unknown')}\")\n",
        "                print(f\"   ì¶”ì²œ ì ìˆ˜: {top_rec.get('recommendation_score', 0):.1%}\")\n",
        "\n",
        "            total_score += evaluation['percentage']\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}\")\n",
        "            results.append({\n",
        "                'scenario': scenario['category'],\n",
        "                'evaluation': {'score': 0, 'percentage': 0, 'grade': 'F (ì˜¤ë¥˜)'}\n",
        "            })\n",
        "\n",
        "    # ì „ì²´ ê²°ê³¼ ìš”ì•½\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    avg_score = total_score / len(test_scenarios) if test_scenarios else 0\n",
        "    overall_grade = get_grade(avg_score)\n",
        "\n",
        "    print(f\"\\nğŸ¯ ì „ì²´ í‰ê·  ì ìˆ˜: {avg_score:.1f}% ({overall_grade})\")\n",
        "\n",
        "    # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼\n",
        "    print(f\"\\nğŸ“‹ ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ê²°ê³¼:\")\n",
        "    for result in results:\n",
        "        eval_data = result['evaluation']\n",
        "        print(f\"   {result['scenario']}: {eval_data.get('percentage', 0):.1f}% ({eval_data.get('grade', 'N/A')})\")\n",
        "\n",
        "    # ì„±ëŠ¥ ë¶„ì„\n",
        "    print(f\"\\nğŸ” ì„±ëŠ¥ ë¶„ì„:\")\n",
        "    excellent_count = sum(1 for r in results if r['evaluation'].get('percentage', 0) >= 90)\n",
        "    good_count = sum(1 for r in results if 80 <= r['evaluation'].get('percentage', 0) < 90)\n",
        "    average_count = sum(1 for r in results if 70 <= r['evaluation'].get('percentage', 0) < 80)\n",
        "    poor_count = sum(1 for r in results if r['evaluation'].get('percentage', 0) < 70)\n",
        "\n",
        "    print(f\"   ğŸ† ìš°ìˆ˜ (90% ì´ìƒ): {excellent_count}ê°œ\")\n",
        "    print(f\"   âœ… ì–‘í˜¸ (80-89%): {good_count}ê°œ\")\n",
        "    print(f\"   âš ï¸ ë³´í†µ (70-79%): {average_count}ê°œ\")\n",
        "    print(f\"   âŒ ë¯¸í¡ (70% ë¯¸ë§Œ): {poor_count}ê°œ\")\n",
        "\n",
        "    # ê°œì„  ì œì•ˆ\n",
        "    print(f\"\\nğŸ’¡ ê°œì„  ì œì•ˆ:\")\n",
        "    if avg_score >= 90:\n",
        "        print(\"   ğŸ‰ ë§¤ìš° ìš°ìˆ˜í•œ ì„±ëŠ¥ì…ë‹ˆë‹¤! í˜„ì¬ ìƒíƒœ ìœ ì§€í•˜ì„¸ìš”.\")\n",
        "    elif avg_score >= 80:\n",
        "        print(\"   ğŸ‘ ì–‘í˜¸í•œ ì„±ëŠ¥ì…ë‹ˆë‹¤. ì„¸ë¶€ ê¸°ëŠ¥ ê°œì„ ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.\")\n",
        "    elif avg_score >= 70:\n",
        "        print(\"   âš ï¸ í‰ê· ì ì¸ ì„±ëŠ¥ì…ë‹ˆë‹¤. ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        print(\"   ğŸ”§ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ì „ì²´ì ì¸ ì‹œìŠ¤í…œ ì ê²€ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "p0AbP4GqSbFk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "4IPWz6_2SbbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ì‚¬ì „ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Colabì—ì„œ ìµœì´ˆ 1íšŒë§Œ)\n",
        "\n",
        "!pip install openai==0.28\n",
        "\n",
        "# âœ… OpenAI API í‚¤ ì„¤ì •\n",
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# âœ… OpenAI ê¸°ë°˜ ì¶”ì²œ ì‚¬ìœ  ìƒì„± í•¨ìˆ˜\n",
        "def generate_openai_recommendation_reason(user_input: str, top_mattresses: List[Dict]) -> str:\n",
        "    \"\"\"\n",
        "    OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì²œ ì‚¬ìœ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±\n",
        "    \"\"\"\n",
        "    mattress_descriptions = \"\\n\".join([\n",
        "        f\"{i+1}. {m['name']} ({m['brand']}) - {m['type']}, {m['firmness']}, {m['price']:,}ì›\"\n",
        "        for i, m in enumerate(top_mattresses)\n",
        "    ])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "ë‹¹ì‹ ì€ ì¹¨ëŒ€ ë° ìˆ˜ë©´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì´ ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤:\n",
        "\"{user_input}\"\n",
        "\n",
        "ì•„ë˜ëŠ” ì¶”ì²œëœ ë§¤íŠ¸ë¦¬ìŠ¤ë“¤ì…ë‹ˆë‹¤:\n",
        "{mattress_descriptions}\n",
        "\n",
        "ê° ì¶”ì²œ ì œí’ˆì´ ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì— ì–¼ë§ˆë‚˜ ì˜ ë§ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì¶”ì²œ ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",  # ë˜ëŠ” gpt-4 ì‚¬ìš© ê°€ëŠ¥\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì—ê²Œ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì¶”ì²œí•˜ê³  ê·¸ ì´ìœ ë¥¼ ì„¤ë“ë ¥ ìˆê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"[OpenAI ì‘ë‹µ ì‹¤íŒ¨: {e}]\"\n",
        "\n",
        "# âœ… OpenAI í†µí•©í˜• ëŒ€í™” í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
        "def interactive_test():\n",
        "    \"\"\"OpenAI í†µí•© ëŒ€í™”í˜• AI Agent í…ŒìŠ¤íŠ¸\"\"\"\n",
        "    print(\"\\nğŸ’¬ ëŒ€í™”í˜• AI Agent í…ŒìŠ¤íŠ¸ (OpenAI í†µí•©)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•´ì„œ AI Agentë¥¼ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!\")\n",
        "    print(\"ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\\n\")\n",
        "\n",
        "    if 'ai_agent' not in globals():\n",
        "        print(\"âŒ AI Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    conversation_count = 0\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"ğŸ¤” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
        "\n",
        "            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'ê·¸ë§Œ']:\n",
        "                print(\"ğŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤!\")\n",
        "                break\n",
        "\n",
        "            if not user_input:\n",
        "                print(\"âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
        "                continue\n",
        "\n",
        "            conversation_count += 1\n",
        "            print(f\"\\nğŸ¤– AI Agent ë¶„ì„ ì¤‘... (ì§ˆë¬¸ #{conversation_count})\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "            # ê¸°ì¡´ AI Agent ì¶”ì²œ ìˆ˜í–‰\n",
        "            result = ai_agent.recommend_mattresses(user_input)\n",
        "\n",
        "            if result.get('success'):\n",
        "                recommendations = result.get('recommendations', [])\n",
        "                user_prefs = result.get('user_preferences', {})\n",
        "\n",
        "                print(f\"âœ… ë¶„ì„ ì™„ë£Œ! {len(recommendations)}ê°œì˜ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\\n\")\n",
        "\n",
        "                print(\"ğŸ“Š ë¶„ì„ëœ ì„ í˜¸ë„:\")\n",
        "                if user_prefs.get('budget'):\n",
        "                    print(f\"   ğŸ’° ì˜ˆì‚°: {user_prefs['budget']:,}ì›\")\n",
        "                if user_prefs.get('health_issues'):\n",
        "                    print(f\"   ğŸ¥ ê±´ê°• ê´€ë ¨: {', '.join(user_prefs['health_issues'])}\")\n",
        "                if user_prefs.get('sleep_position'):\n",
        "                    print(f\"   ğŸ˜´ ìˆ˜ë©´ìì„¸: {user_prefs['sleep_position']}\")\n",
        "                if user_prefs.get(\"allergies\"):\n",
        "                    print(f\"   ğŸ§¼ ë¯¼ê° ì¡°ê±´: ì•Œë ˆë¥´ê¸° ìˆìŒ\")\n",
        "                if user_prefs.get('temperature_preference'):\n",
        "                    print(f\"   ğŸŒ¡ï¸ ì˜¨ë„ ì„ í˜¸: {user_prefs['temperature_preference']}\")\n",
        "                if user_prefs.get(\"firmness_preference\"):\n",
        "                    print(f\"   ğŸ’ª ê²½ë„ ì„ í˜¸: {user_prefs['firmness_preference']}\")\n",
        "                if user_prefs.get(\"partner\"):\n",
        "                    print(f\"   ğŸ‘¥ ì»¤í”Œ ìˆ˜ë©´ ì—¬ë¶€: ì˜ˆ\")\n",
        "\n",
        "                print(f\"\\nğŸ† ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤:\")\n",
        "                for i, rec in enumerate(recommendations[:3], 1):\n",
        "                    print(f\"   {i}. {rec.get('name', 'Unknown')}\")\n",
        "                    print(f\"      ë¸Œëœë“œ: {rec.get('brand', 'Unknown')}\")\n",
        "                    print(f\"      ê°€ê²©: {rec.get('price', 0):,}ì›\")\n",
        "                    print(f\"      íƒ€ì…: {rec.get('type', 'Unknown')}\")\n",
        "                    print()\n",
        "\n",
        "                # âœ… OpenAI ê¸°ë°˜ ì¶”ì²œ ì‚¬ìœ  ì¶”ê°€\n",
        "                print(\"ğŸ’¡ ì¶”ì²œ ì‚¬ìœ :\")\n",
        "                openai_reason = generate_openai_recommendation_reason(user_input, recommendations[:3])\n",
        "                print(openai_reason)\n",
        "\n",
        "            else:\n",
        "                print(\"âŒ ì¶”ì²œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "                print(\"ğŸ’¡ ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nğŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
      ],
      "metadata": {
        "id": "0vY44UNJOkHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d5c0c8-b40d-4a26-e4f0-4138bdcf5bdb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) ì‚¬ìš©ì ì§ˆë¬¸ í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "dvik-LZDS8z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv0-FNV3Sr3l",
        "outputId": "ae21c344-6210-45f3-83c7-c90f79bf28b3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ’¬ ëŒ€í™”í˜• AI Agent í…ŒìŠ¤íŠ¸ (OpenAI í†µí•©)\n",
            "==================================================\n",
            "ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•´ì„œ AI Agentë¥¼ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!\n",
            "ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
            "\n",
            "ğŸ¤” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: í”„ë¦¬ë¯¸ì—„ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”. ìµœê³  í’ˆì§ˆì˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
            "\n",
            "ğŸ¤– AI Agent ë¶„ì„ ì¤‘... (ì§ˆë¬¸ #1)\n",
            "------------------------------------------------------------\n",
            "\n",
            "ğŸ¯ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘\n",
            "ì‚¬ìš©ì ì…ë ¥: 'í”„ë¦¬ë¯¸ì—„ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”. ìµœê³  í’ˆì§ˆì˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.'\n",
            "ğŸ” ì‚¬ìš©ì ì…ë ¥ ë¶„ì„: 'í”„ë¦¬ë¯¸ì—„ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”. ìµœê³  í’ˆì§ˆì˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.'\n",
            "ğŸ“Š ë¶„ì„ëœ ì„ í˜¸ë„: {'sleep_position': '', 'body_weight': '', 'budget': 0, 'health_issues': [], 'temperature_preference': '', 'partner': False, 'firmness_preference': ''}\n",
            "ğŸ¯ Function Call: collect_user_preferences\n",
            "ğŸ” Function Call: search_mattresses('í”„ë¦¬ë¯¸ì—„ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ê³  ìˆì–´ìš”. ìµœê³  í’ˆì§ˆì˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.')\n",
            "ğŸ“Š Function Call: calculate_recommendation_score\n",
            "ğŸ“Š Function Call: calculate_recommendation_score\n",
            "ğŸ“Š Function Call: calculate_recommendation_score\n",
            "ğŸ“Š Function Call: calculate_recommendation_score\n",
            "ğŸ“Š Function Call: calculate_recommendation_score\n",
            "ğŸ“Š Function Call: calculate_recommendation_score\n",
            "ğŸ“Š Function Call: calculate_recommendation_score\n",
            "ğŸ“Š Function Call: calculate_recommendation_score\n",
            "ğŸ¯ Function Call: generate_recommendation\n",
            "âœ… ë¶„ì„ ì™„ë£Œ! 3ê°œì˜ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n",
            "\n",
            "ğŸ“Š ë¶„ì„ëœ ì„ í˜¸ë„:\n",
            "\n",
            "ğŸ† ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤:\n",
            "   1. IKEA HYLLESTAD ëª¨ë¸ 60\n",
            "      ë¸Œëœë“œ: IKEA\n",
            "      ê°€ê²©: 1,750,752ì›\n",
            "      íƒ€ì…: í•˜ì´ë¸Œë¦¬ë“œ\n",
            "\n",
            "   2. IKEA HYLLESTAD ëª¨ë¸ 15\n",
            "      ë¸Œëœë“œ: IKEA\n",
            "      ê°€ê²©: 344,153ì›\n",
            "      íƒ€ì…: ì ¤ë©”ëª¨ë¦¬í¼\n",
            "\n",
            "   3. ACE HYBRID TECH ëª¨ë¸ 28\n",
            "      ë¸Œëœë“œ: ACE\n",
            "      ê°€ê²©: 2,626,607ì›\n",
            "      íƒ€ì…: ë©”ëª¨ë¦¬í¼\n",
            "\n",
            "ğŸ’¡ ì¶”ì²œ ì‚¬ìœ :\n",
            "ê³ ê°ë‹˜, ì œê°€ ì¶”ì²œë“œë¦¬ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ëŠ” IKEA HYLLESTAD ëª¨ë¸ 60ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ í•˜ì´ë¸Œë¦¬ë“œë¡œ ìŠ¤í”„ë§ê³¼ ë©”ëª¨ë¦¬í¼ì´ ì¡°í™”ë¡­ê²Œ ê²°í•©ë˜ì–´ ìµœê³ ì˜ í¸ì•ˆí•¨ì„ ì œê³µí•©ë‹ˆë‹¤. ì†Œí”„íŠ¸-ë¯¸ë””ì›€ ê°•ë„ë¡œ í¸ì•ˆí•œ ì§€ì§€ë ¥ì„ ì œê³µí•˜ë©°, ê°€ê²© ëŒ€ë¹„ íƒì›”í•œ í’ˆì§ˆì„ ìë‘í•©ë‹ˆë‹¤. 1,750,752ì›ì˜ ê°€ê²©ì€ ê·¸ë§Œí¼ì˜ í¸ì•ˆí•¨ê³¼ ì§€ì§€ë ¥ì„ ì œê³µí•œë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ë°˜ë©´, IKEA HYLLESTAD ëª¨ë¸ 15ì€ ì ¤ë©”ëª¨ë¦¬í¼ìœ¼ë¡œ ì œì‘ë˜ì–´ ë¶€ë“œëŸ½ê³  ì¿ ì…˜ê°ì´ ì¢‹ì€ ì œí’ˆì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ê°€ê²©ëŒ€ë¹„ ë‚´êµ¬ì„± ë©´ì—ì„œëŠ” ëª¨ë¸ 60ì— ë¹„í•´ ì•½ê°„ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ë§ˆì§€ë§‰ìœ¼ë¡œ ACE HYBRID TECH ëª¨ë¸ 28ì€ ë©”ëª¨ë¦¬í¼ìœ¼ë¡œ ì œì‘ë˜ì—ˆìœ¼ë©°, ë¯¸ë””ì›€-í•˜ë“œí•œ ê°•ë„ë¡œ ì§€ì§€ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê°€ê²©ì´ ë‹¤ì†Œ ë†’ì•„ì„œ ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ ë©´ì—ì„œëŠ” ë‹¤ì†Œ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ìµœê³  í’ˆì§ˆì˜ ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ìœ¼ì‹ ë‹¤ë©´, IKEA HYLLESTAD ëª¨ë¸ 60ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. í•˜ì´ë¸Œë¦¬ë“œ ë””ìì¸ìœ¼ë¡œ ìµœì ì˜ í¸ì•ˆí•¨ê³¼ ì§€ì§€ë ¥ì„ ì œê³µí•˜ë©°, ê°€ê²©ëŒ€ë¹„ íƒì›”í•œ ì„ íƒì´ ë  ê²ƒì…ë‹ˆë‹¤. ì´ ë§¤íŠ¸ë¦¬ìŠ¤ëŠ” ë‹¹ì‹ ì˜ ìˆ˜ë©´ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤.\n",
            "\n",
            "============================================================\n",
            "\n",
            "ğŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤!\n"
          ]
        }
      ]
    }
  ]
}